{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a9f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit import RDConfig\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import multiprocessing\n",
    "#from joblib import Parallel, delayed\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19ef3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "Sun Nov 20 13:07:35 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   31C    P8    14W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a14248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "050e98e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mip-10-0-101-229\u001b[m  Sun Nov 20 13:07:35 2022  \u001b[1m\u001b[30m520.61.05\u001b[m\r\n",
      "\u001b[36m[0]\u001b[m \u001b[34mTesla T4\u001b[m |\u001b[31m 32°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  404\u001b[m / \u001b[33m15360\u001b[m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de149c50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593ce43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from skmultilearn.dataset import load_from_arff, load_dataset_dump\n",
    "import copy\n",
    "import datetime\n",
    "import jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d2eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import pandas as pd\n",
    "import copy\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05404d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import str\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "import arff\n",
    "import bz2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "from os import environ\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "from os.path import exists\n",
    "from os.path import expanduser\n",
    "from os.path import isdir\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "from os import makedirs\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba95f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd71162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_label = pd.read_csv('dataset.csv',index_col=0)\n",
    "#label = label.iloc[:12,:]\n",
    "dat_smiles = pd.read_csv('smiles.csv', index_col=0)\n",
    "s = dat_smiles.to_dict()\n",
    "dict_smile = s['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124de90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_labels = dat_label.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f6cf1",
   "metadata": {},
   "source": [
    "del 11980947,5287407,24238,44475014,62074,11686063,133082064,16211610,173849,CID23308253,24753271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e3cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def szymanski_ts_eq_fold(n_splits, y):\n",
    "\n",
    "    y_train = lil_matrix(y)\n",
    "\n",
    "    n_samples = y_train.shape[0] #593\n",
    "    n_labels = y_train.shape[1] #6\n",
    "\n",
    "    percentage_per_fold = [1/float(n_splits) for i in range(n_splits)]\n",
    "    desired_samples_per_fold = np.array([percentage_per_fold[i]*n_samples for i in range(n_splits)]) #59.3\n",
    "\n",
    "    folds = [[] for i in range(n_splits)] #10 lists\n",
    "\n",
    "    samples_with_label = [[] for i in range(n_labels)]\n",
    "\n",
    "    for sample, labels in enumerate(y_train.rows):\n",
    "        for label in labels:\n",
    "            samples_with_label[label].append(sample)\n",
    "    # labelpair based sample size\n",
    "            \n",
    "    samples_with_labelpairs = {}\n",
    "    for row, labels in enumerate(y_train.rows):\n",
    "        pairs = [(a, b) for b in labels for a in labels if a <= b]\n",
    "        for p in pairs:\n",
    "            if p not in samples_with_labelpairs:\n",
    "                samples_with_labelpairs[p] = []\n",
    "            samples_with_labelpairs[p].append(row)\n",
    "\n",
    "    desired_samples_per_labelpair_per_fold = {k : [len(v)*i for i in percentage_per_fold] for k,v in samples_with_labelpairs.items()}\n",
    "\n",
    "    labels_of_edges = samples_with_labelpairs.keys() # 20 pairs\n",
    "    labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges] #XXXXXX\n",
    "    # labelpair based sample size\n",
    "    \n",
    "    rows_used = {i : False for i in range(n_samples)}\n",
    "    total_labeled_samples_available = sum(labeled_samples_available) #1723\n",
    "    old_l=None\n",
    "\n",
    "    while total_labeled_samples_available > 0:\n",
    "        l = list(labels_of_edges)[np.argmin(np.ma.masked_equal(labeled_samples_available, 0, copy=False))]\n",
    "\n",
    "        while len(samples_with_labelpairs[l])>0:\n",
    "\n",
    "            row = samples_with_labelpairs[l].pop()\n",
    "            if rows_used[row]:\n",
    "                continue\n",
    "\n",
    "            max_val = max(desired_samples_per_labelpair_per_fold[l])\n",
    "            M = np.where(np.array(desired_samples_per_labelpair_per_fold[l])==max_val)[0]\n",
    "            #print(l, M, len(M))\n",
    "\n",
    "            m = None\n",
    "            if len(M) == 1:\n",
    "                m = M[0]\n",
    "            else:\n",
    "                max_val = max(desired_samples_per_fold[M])\n",
    "                M_bis = np.where(np.array(desired_samples_per_fold)==max_val)[0]\n",
    "                M_bis = np.array([x for x in M_bis if x in M])\n",
    "                m = np.random.choice(M_bis, 1)[0]\n",
    "\n",
    "            folds[m].append(row)\n",
    "            rows_used[row]=True #----\n",
    "            desired_samples_per_labelpair_per_fold[l][m]-=1\n",
    "            if desired_samples_per_labelpair_per_fold[l][m] <0:\n",
    "                desired_samples_per_labelpair_per_fold[l][m]=0\n",
    "\n",
    "            for i in samples_with_labelpairs.keys():\n",
    "                if row in samples_with_labelpairs[i]:\n",
    "                    samples_with_labelpairs[i].remove(row)\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]-=1\n",
    "\n",
    "                if desired_samples_per_labelpair_per_fold[i][m] <0:\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]=0\n",
    "            desired_samples_per_fold[m]-=1\n",
    "\n",
    "        labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges]\n",
    "        total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "        available_samples = [i for i, v in rows_used.items() if not v]\n",
    "        samples_left = len(available_samples)\n",
    "\n",
    "\n",
    "    assert (samples_left + sum(map(len, folds))) == n_samples\n",
    "\n",
    "    while samples_left>0:\n",
    "        row = available_samples.pop()\n",
    "        rows_used[row]=True\n",
    "        fold_selected = np.random.choice(np.where(desired_samples_per_fold>0)[0], 1)[0]\n",
    "        folds[fold_selected].append(row)\n",
    "        samples_left-=1\n",
    "\n",
    "    assert sum(map(len, folds)) == n_samples\n",
    "    assert len([i for i, v in rows_used.items() if not v])==0\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c95d04a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5596x91 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22713 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.sparse.lil_matrix(dat_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14e84982",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "folds =szymanski_ts_eq_fold(n_splits, dat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab91d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--model'], dest='model', nargs=None, const=None, default='MPNN', type=<class 'str'>, choices=None, help='MPNN model name [MPNN, MPNNv2, MPNNv3]', metavar=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parser check\n",
    "def restricted_float(x, inter):\n",
    "    x = float(x)\n",
    "    if x < inter[0] or x > inter[1]:\n",
    "        raise argparse.ArgumentTypeError(\"%r not in range [1e-5, 1e-4]\"%(x,))\n",
    "    return x\n",
    "\n",
    "# Argument parser\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Neural message passing')\n",
    "\n",
    "parser.add_argument('--dataset', default='qm9', help='QM9')\n",
    "parser.add_argument('--datasetPath', default='/home/taobai/Documents/Model/MPNN/mpnn-data/qm9/dsgdb9nsd/', help='dataset path')\n",
    "parser.add_argument('--logPath', default='./log/qm9/mpnn/', help='log path')\n",
    "parser.add_argument('--plotLr', default=False, help='allow plotting the data')\n",
    "parser.add_argument('--plotPath', default='./plot/qm9/mpnn/', help='plot path')\n",
    "#parser.add_argument('--resume', default='./checkpoint/qm9/mpnn/',\n",
    "#                    help='path to latest checkpoint')\n",
    "\n",
    "# Optimization Options\n",
    "parser.add_argument('--batch-size', type=int, default=10, metavar='N',\n",
    "                    help='Input batch size for training (default: 20)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Enables CUDA training')\n",
    "parser.add_argument('--epochs', type=int, default=5, metavar='N',\n",
    "                    help='Number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=lambda x: restricted_float(x, [1e-5, 1e-2]), default=1e-3, metavar='LR',\n",
    "                    help='Initial learning rate [1e-5, 5e-4] (default: 1e-4)')\n",
    "parser.add_argument('--lr-decay', type=lambda x: restricted_float(x, [.01, 1]), default=0.6, metavar='LR-DECAY',\n",
    "                    help='Learning rate decay factor [.01, 1] (default: 0.6)')\n",
    "parser.add_argument('--schedule', type=list, default=[0.1, 0.9], metavar='S',\n",
    "                    help='Percentage of epochs to start the learning rate decay [0, 1] (default: [0.1, 0.9])')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum (default: 0.9)')\n",
    "# i/o\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='How many batches to wait before logging training status')\n",
    "# Accelerating\n",
    "parser.add_argument('--prefetch', type=int, default=4, help='Pre-fetching threads.')\n",
    "\n",
    "# Model modification\n",
    "parser.add_argument('--model', type=str,help='MPNN model name [MPNN, MPNNv2, MPNNv3]',\n",
    "                        default='MPNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5b30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='qm9', datasetPath='/home/taobai/Documents/Model/MPNN/mpnn-data/qm9/dsgdb9nsd/', logPath='./log/qm9/mpnn/', plotLr=False, plotPath='./plot/qm9/mpnn/', batch_size=10, no_cuda=False, epochs=5, lr=0.001, lr_decay=0.6, schedule=[0.1, 0.9], momentum=0.9, log_interval=100, prefetch=4, model='MPNN')\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c234a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_er1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f98f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e882a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_graph_reader(CID):\n",
    "    smiles = dict_smile[CID]\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    m = Chem.AddHs(m)\n",
    "   \n",
    "    g = nx.Graph()\n",
    "    # Create nodes\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        atom_i = m.GetAtomWithIdx(i)\n",
    "\n",
    "        g.add_node(i, a_type=atom_i.GetSymbol(), a_num=atom_i.GetAtomicNum(), acceptor=0, donor=0,\n",
    "                   aromatic=atom_i.GetIsAromatic(), hybridization=atom_i.GetHybridization(),\n",
    "                   num_h=atom_i.GetTotalNumHs())\n",
    "\n",
    "\n",
    "    # Read Edges\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        for j in range(0, m.GetNumAtoms()):\n",
    "            e_ij = m.GetBondBetweenAtoms(i, j)\n",
    "            if e_ij is not None:\n",
    "                g.add_edge(i, j, b_type=e_ij.GetBondType())\n",
    "            else:\n",
    "                # Unbonded\n",
    "                g.add_edge(i, j, b_type=None)\n",
    "\n",
    "    l = list(dat_label[CID].values)           \n",
    "                \n",
    "    return g , l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f86a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_edges(g):\n",
    "    remove_edges = []\n",
    "    e={}    \n",
    "    for n1, n2, d in g.edges(data=True):\n",
    "        e_t = []\n",
    "        # Raw distance function\n",
    "        if d['b_type'] is None:\n",
    "            remove_edges += [(n1, n2)]\n",
    "        else:\n",
    "            #e_t.append(d['distance'])\n",
    "            e_t += [int(d['b_type'] == x) for x in [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE,\n",
    "                                                    rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]]\n",
    "        if e_t:\n",
    "            e[(n1, n2)] = e_t\n",
    "    for edg in remove_edges:\n",
    "        g.remove_edge(*edg)    \n",
    "    \n",
    "    return nx.to_numpy_matrix(g), e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea03898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_nodes(g, hydrogen=False):\n",
    "    h = []\n",
    "    for n, d in g.nodes(data=True): \n",
    "        h_t = []\n",
    "        # Atom type (One-hot H, C, N, O F)\n",
    "        h_t += [int(d['a_type'] == x) for x in ['H', 'C', 'N', 'O', 'F']]\n",
    "        # Atomic number\n",
    "        h_t.append(d['a_num'])\n",
    "        # Acceptor\n",
    "        h_t.append(d['acceptor'])\n",
    "        # Donor\n",
    "        h_t.append(d['donor'])\n",
    "        # Aromatic\n",
    "        h_t.append(int(d['aromatic']))\n",
    "        # If number hydrogen is used as a\n",
    "        if hydrogen:\n",
    "            h_t.append(d['num_h'])\n",
    "        h.append(h_t)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b2a63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qm9():\n",
    "#class Qm9(data.Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self, idx, vertex_transform=qm9_nodes, edge_transform=qm9_edges,\n",
    "                 target_transform=None, e_representation='raw_distance'):\n",
    "        self.idx = idx\n",
    "        self.vertex_transform = vertex_transform\n",
    "        self.edge_transform = edge_transform\n",
    "        self.target_transform = target_transform\n",
    "        #化学分子距离度量方式，有三种，这里用的是'raw_distance'\n",
    "        self.e_representation = e_representation\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #读图，返回networkx类型的图，标签list\n",
    "        #self.ids[index]是根据index得到化学分子文件名\n",
    "        #self.root是路径\n",
    "        g, target = xyz_graph_reader(self.idx[index])\n",
    "        if self.vertex_transform is not None:\n",
    "            h = self.vertex_transform(g)\n",
    "\n",
    "        if self.edge_transform is not None:\n",
    "            g, e = self.edge_transform(g)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        #g：邻接矩阵\n",
    "        #h：每个点的特征（list of list）\n",
    "        #e：词典，key是边，value是特征\n",
    "        #target：标签list\n",
    "        return (g, h, e), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    def set_target_transform(self, target_transform):\n",
    "        self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354b3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4c695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "227578a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = folds[2]+folds[3]+folds[4]+folds[5]+folds[6]+folds[7]+folds[8]+folds[9]\n",
    "valid_ids = [dat_label.columns[i] for i in folds[0]]\n",
    "test_ids = [dat_label.columns[i] for i in folds[1]]\n",
    "train_ids =  [dat_label.columns[i] for i in idx]\n",
    "\n",
    "data_train = Qm9(train_ids, edge_transform=qm9_edges, e_representation='raw_distance')\n",
    "data_valid = Qm9(valid_ids, edge_transform=qm9_edges, e_representation='raw_distance')\n",
    "data_test = Qm9(test_ids, edge_transform=qm9_edges, e_representation='raw_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e6d3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87db4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one graph\n",
    "g_tuple, l = data_train[0]\n",
    "g, h_t, e = g_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bebaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(obj, start, end):\n",
    "    vals = []\n",
    "    for i in range(start, end):\n",
    "        vals.append(obj[i][1])\n",
    "    return vals\n",
    "def get_graph_stats(graph_obj_handle):\n",
    "    inputs = len(graph_obj_handle)\n",
    "    res = get_values(graph_obj_handle, 0, inputs) \n",
    "    param = np.array(res)\n",
    "    \n",
    "    stat_dict = {}\n",
    "    \n",
    "    stat_dict['target_mean'] = np.mean(param, axis=0)\n",
    "    stat_dict['target_std'] = np.std(param, axis=0)\n",
    "\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "658957cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_dict = get_graph_stats(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54e2ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_target_transform was defined in Class Qm9\n",
    "data_train.set_target_transform(lambda x:x)\n",
    "data_valid.set_target_transform(lambda x: x)\n",
    "data_test.set_target_transform(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd8dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be9d6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_g(batch):\n",
    "\n",
    "    batch_sizes = np.max(np.array([[len(input_b[1]), len(input_b[1][0]), len(input_b[2]),\n",
    "                                len(list(input_b[2].values())[0])]\n",
    "                                if input_b[2] else\n",
    "                                [len(input_b[1]), len(input_b[1][0]), 0,0]\n",
    "                                for (input_b, target_b) in batch]), axis=0)\n",
    "\n",
    "    g = np.zeros((len(batch), batch_sizes[0], batch_sizes[0]))\n",
    "    h = np.zeros((len(batch), batch_sizes[0], batch_sizes[1]))\n",
    "    e = np.zeros((len(batch), batch_sizes[0], batch_sizes[0], batch_sizes[3]))\n",
    "\n",
    "    target = np.zeros((len(batch), len(batch[0][1])))\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "\n",
    "        num_nodes = len(batch[i][0][1])\n",
    "\n",
    "        # Adjacency matrix\n",
    "        g[i, 0:num_nodes, 0:num_nodes] = batch[i][0][0]\n",
    "\n",
    "        # Node features\n",
    "        h[i, 0:num_nodes, :] = batch[i][0][1]\n",
    "\n",
    "        # Edges\n",
    "        for edge in batch[i][0][2].keys():\n",
    "            e[i, edge[0], edge[1], :] = batch[i][0][2][edge]\n",
    "            e[i, edge[1], edge[0], :] = batch[i][0][2][edge]\n",
    "\n",
    "        # Target\n",
    "        target[i, :] = batch[i][1]\n",
    "\n",
    "    g = torch.FloatTensor(g)\n",
    "    h = torch.FloatTensor(h)\n",
    "    e = torch.FloatTensor(e)\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    return g, h, e, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99e743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#注意这里面的collate_g函数,在utils里面\n",
    "train_loader = torch.utils.data.DataLoader(data_train,\n",
    "                                           batch_size=args.batch_size,shuffle=True, collate_fn=collate_g,\n",
    "                                           num_workers=args.prefetch, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(data_valid,\n",
    "                                           batch_size=args.batch_size, collate_fn=collate_g,\n",
    "                                           num_workers=args.prefetch, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=args.batch_size, collate_fn=collate_g,\n",
    "                                          num_workers=args.prefetch, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0bb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf39dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c055cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, hlayers=(91, 256, 128)):\n",
    "        super(NNet, self).__init__()\n",
    "        self.n_hlayers = len(hlayers)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(n_in, hlayers[i]) if i == 0 else\n",
    "                                  nn.Linear(hlayers[i-1], n_out) if i == self.n_hlayers else\n",
    "                                  nn.Linear(hlayers[i-1], hlayers[i]) for i in range(self.n_hlayers+1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.contiguous().view(-1, self.num_flat_features(x))\n",
    "        for i in range(self.n_hlayers):\n",
    "            x = F.relu(self.fcs[i](x))\n",
    "        x = self.fcs[-1](x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b8d2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "171cb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, message_def='mpnn', args={}):\n",
    "        super(MessageFunction, self).__init__()\n",
    "        self.m_definition = ''\n",
    "        self.m_function = None\n",
    "        self.args = {}\n",
    "        self.__set_message(message_def, args)\n",
    "\n",
    "    # Message from h_v to h_w through e_vw\n",
    "    def forward(self, h_v, h_w, e_vw, args=None):\n",
    "        return self.m_function(h_v, h_w, e_vw, args)\n",
    "\n",
    "    # Set a message function\n",
    "    def __set_message(self, message_def, args={}):\n",
    "        self.m_definition = message_def.lower()\n",
    "\n",
    "        self.m_function = {\n",
    "                    'duvenaud':         self.m_duvenaud,\n",
    "                    'intnet':             self.m_intnet,\n",
    "                    'mpnn':             self.m_mpnn,\n",
    "                }.get(self.m_definition, None)\n",
    "\n",
    "        if self.m_function is None:\n",
    "            print('WARNING!: Message Function has not been set correctly\\n\\tIncorrect definition ' + message_def)\n",
    "            quit()\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud': self.init_duvenaud,            \n",
    "            'intnet':     self.init_intnet,\n",
    "            'mpnn':     self.init_mpnn\n",
    "        }.get(self.m_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "        self.m_size = {\n",
    "                'duvenaud':     self.out_duvenaud,            \n",
    "                'intnet':         self.out_intnet,\n",
    "                'mpnn':         self.out_mpnn\n",
    "            }.get(self.m_definition, None)\n",
    "\n",
    "    # Get the name of the used message function\n",
    "    def get_definition(self):\n",
    "        return self.m_definition\n",
    "\n",
    "    # Get the message function arguments\n",
    "    def get_args(self):\n",
    "        return self.args\n",
    "\n",
    "    # Get Output size\n",
    "    def get_out_size(self, size_h, size_e, args=None):\n",
    "        return self.m_size(size_h, size_e, args)\n",
    "    \n",
    "    \n",
    "    # Duvenaud et al. (2015), Convolutional Networks for Learning Molecular Fingerprints\n",
    "    def m_duvenaud(self, h_v, h_w, e_vw, args):\n",
    "        m = torch.cat([h_w, e_vw], 2)\n",
    "        return m\n",
    "\n",
    "    def out_duvenaud(self, size_h, size_e, args):\n",
    "        return size_h + size_e\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args \n",
    "\n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def m_intnet(self, h_v, h_w, e_vw, args):\n",
    "        m = torch.cat([h_v[:, None, :].expand_as(h_w), h_w, e_vw], 2)\n",
    "        b_size = m.size()\n",
    "\n",
    "        m = m.view(-1, b_size[2])\n",
    "\n",
    "        m = self.learn_modules[0](m)\n",
    "        m = m.view(b_size[0], b_size[1], -1)\n",
    "        return m\n",
    "\n",
    "    def out_intnet(self, size_h, size_e, args):\n",
    "        return self.args['out']\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['out']))\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    # Gilmer et al. (2017), Neural Message Passing for Quantum Chemistry\n",
    "    def m_mpnn(self, h_v, h_w, e_vw, opt={}):\n",
    "        # Matrices for each edge\n",
    "        edge_output = self.learn_modules[0](e_vw)\n",
    "        edge_output = edge_output.view(-1, self.args['out'], self.args['in'])\n",
    "\n",
    "        #h_w_rows = h_w[..., None].expand(h_w.size(0), h_v.size(1), h_w.size(1)).contiguous()\n",
    "        h_w_rows = h_w[..., None].expand(h_w.size(0), h_w.size(1), h_v.size(1)).contiguous()\n",
    "\n",
    "        h_w_rows = h_w_rows.view(-1, self.args['in'])\n",
    "\n",
    "        h_multiply = torch.bmm(edge_output, torch.unsqueeze(h_w_rows,2))\n",
    "\n",
    "        m_new = torch.squeeze(h_multiply)\n",
    "\n",
    "        return m_new\n",
    "\n",
    "    def out_mpnn(self, size_h, size_e, args):\n",
    "        return self.args['out']\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix A for each edge label.\n",
    "        learn_modules.append(NNet(n_in=params['edge_feat'], n_out=(params['in']*params['out'])))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "def0681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UpdateFunction.py: Updates the nodes using the previous state and the message.\n",
    "\n",
    "class UpdateFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, update_def='nn', args={}):\n",
    "        super(UpdateFunction, self).__init__()\n",
    "        self.u_definition = ''\n",
    "        self.u_function = None\n",
    "        self.args = {}\n",
    "        self.__set_update(update_def, args)\n",
    "\n",
    "    # Update node hv given message mv\n",
    "    def forward(self, h_v, m_v, opt={}):\n",
    "        return self.u_function(h_v, m_v, opt)\n",
    "\n",
    "    # Set update function\n",
    "    def __set_update(self, update_def, args):\n",
    "        self.u_definition = update_def.lower()\n",
    "\n",
    "        self.u_function = {\n",
    "                    'duvenaud':         self.u_duvenaud,            \n",
    "                    'intnet':             self.u_intnet,\n",
    "                    'mpnn':             self.u_mpnn\n",
    "                }.get(self.u_definition, None)\n",
    "\n",
    "        if self.u_function is None:\n",
    "            print('WARNING!: Update Function has not been set correctly\\n\\tIncorrect definition ' + update_def)\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud':         self.init_duvenaud,            \n",
    "            'intnet':             self.init_intnet,\n",
    "            'mpnn':             self.init_mpnn\n",
    "        }.get(self.u_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "    # Get the name of the used update function\n",
    "    def get_definition(self):\n",
    "        return self.u_definition\n",
    "\n",
    "    # Get the update function arguments\n",
    "    def get_args(self):\n",
    "        return self.args\n",
    "    \n",
    "    # Duvenaud\n",
    "    def u_duvenaud(self, h_v, m_v, opt):\n",
    "\n",
    "        param_sz = self.learn_args[0][opt['deg']].size()\n",
    "        parameter_mat = torch.t(self.learn_args[0][opt['deg']])[None, ...].expand(m_v.size(0), param_sz[1], param_sz[0])\n",
    "        \n",
    "        #print(parameter_mat.size())\n",
    "        #print(m_v.size())\n",
    "        #print(torch.transpose(m_v.unsqueeze(-2), 1, 2).size())\n",
    "\n",
    "        #aux = torch.bmm(parameter_mat, torch.transpose(m_v, 1, 2))\n",
    "        aux = torch.bmm(parameter_mat, torch.transpose(m_v.unsqueeze(-2), 1, 2))\n",
    "\n",
    "        return torch.transpose(torch.nn.Sigmoid()(aux), 1, 2)\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        # Filter degree 0 (the message will be 0 and therefore there is no update\n",
    "        args['deg'] = [i for i in params['deg'] if i!=0]\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix H for each degree.\n",
    "        learn_args.append(torch.nn.Parameter(torch.randn(len(args['deg']), args['in'], args['out'])))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args    \n",
    "\n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def u_intnet(self, h_v, m_v, opt):\n",
    "        if opt['x_v'].ndimension():\n",
    "            input_tensor = torch.cat([h_v, opt['x_v'], torch.squeeze(m_v)], 1)\n",
    "        else:\n",
    "            input_tensor = torch.cat([h_v, torch.squeeze(m_v)], 1)\n",
    "\n",
    "        return self.learn_modules[0](input_tensor)\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['out']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    def u_mpnn(self, h_v, m_v, opt={}):\n",
    "        h_in = h_v.view(-1,h_v.size(2))\n",
    "        m_in = m_v.view(-1,m_v.size(2))\n",
    "        h_new = self.learn_modules[0](m_in[None,...],h_in[None,...])[0] # 0 or 1???\n",
    "        return torch.squeeze(h_new).view(h_v.size())\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in_m'] = params['in_m']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # GRU\n",
    "        learn_modules.append(nn.GRU(params['in_m'], params['out']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f66f3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReadoutFunction\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "class ReadoutFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, readout_def='nn', args={}):\n",
    "        super(ReadoutFunction, self).__init__()\n",
    "        self.r_definition = ''\n",
    "        self.r_function = None\n",
    "        self.args = {}\n",
    "        self.__set_readout(readout_def, args)\n",
    "\n",
    "    # Readout graph given node values at las layer\n",
    "    def forward(self, h_v):\n",
    "        return self.r_function(h_v)\n",
    "\n",
    "    # Set a readout function\n",
    "    def __set_readout(self, readout_def, args):\n",
    "        self.r_definition = readout_def.lower()\n",
    "\n",
    "        self.r_function = {\n",
    "                    'duvenaud': self.r_duvenaud,            \n",
    "                    'intnet':     self.r_intnet,\n",
    "                    'mpnn':     self.r_mpnn\n",
    "                }.get(self.r_definition, None)\n",
    "\n",
    "        if self.r_function is None:\n",
    "            print('WARNING!: Readout Function has not been set correctly\\n\\tIncorrect definition ' + readout_def)\n",
    "            quit()\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud': self.init_duvenaud,            \n",
    "            'intnet':     self.init_intnet,\n",
    "            'mpnn':     self.init_mpnn\n",
    "        }.get(self.r_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "    # Get the name of the used readout function\n",
    "    def get_definition(self):\n",
    "        return self.r_definition\n",
    "\n",
    "    # Duvenaud\n",
    "    def r_duvenaud(self, h):\n",
    "        # layers\n",
    "        aux = []\n",
    "        for l in range(len(h)):\n",
    "            param_sz = self.learn_args[l].size()\n",
    "            parameter_mat = torch.t(self.learn_args[l])[None, ...].expand(h[l].size(0), param_sz[1],\n",
    "                                                                                      param_sz[0])\n",
    "\n",
    "            aux.append(torch.transpose(torch.bmm(parameter_mat, torch.transpose(h[l], 1, 2)), 1, 2))\n",
    "\n",
    "            for j in range(0, aux[l].size(1)):\n",
    "                # Mask whole 0 vectors\n",
    "                aux[l][:, j, :] = nn.Softmax()(aux[l][:, j, :].clone())*(torch.sum(aux[l][:, j, :] != 0, 1) > 0)[...,None].expand_as(aux[l][:, j, :]).type_as(aux[l])\n",
    "\n",
    "        aux = torch.sum(torch.sum(torch.stack(aux, 3), 3), 1)\n",
    "        return self.learn_modules[0](torch.squeeze(aux))\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix W for each layer.\n",
    "        for l in range(params['layers']):\n",
    "            learn_args.append(nn.Parameter(torch.randn(params['in'][l], params['out'])))\n",
    "\n",
    "        # learn_modules.append(nn.Linear(params['out'], params['target']))\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['out'], n_out=params['target']))\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args    \n",
    "    \n",
    "    \n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def r_intnet(self, h):\n",
    "\n",
    "        aux = torch.sum(h[-1],1)\n",
    "\n",
    "        return self.learn_modules[0](aux)\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['target']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    def r_mpnn(self, h):\n",
    "\n",
    "        aux = Variable( torch.Tensor(h[0].size(0), self.args['out']).type_as(h[0].data).zero_() )\n",
    "        # For each graph\n",
    "        for i in range(h[0].size(0)):\n",
    "            nn_res = nn.Sigmoid()(self.learn_modules[0](torch.cat([h[0][i,:,:], h[-1][i,:,:]], 1)))*self.learn_modules[1](h[-1][i,:,:])\n",
    "\n",
    "            # Delete virtual nodes\n",
    "            nn_res = (torch.sum(h[0][i,:,:],1)[...,None].expand_as(nn_res)>0).type_as(nn_res)* nn_res\n",
    "\n",
    "            aux[i,:] = torch.sum(nn_res,0)\n",
    "\n",
    "        return aux\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        # i\n",
    "        learn_modules.append(NNet(n_in=2*params['in'], n_out=params['target']))\n",
    "\n",
    "        # j\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['target']))\n",
    "\n",
    "        args['out'] = params['target']\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d155c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "class MPNN(nn.Module):\n",
    "    \"\"\"\n",
    "        MPNN as proposed by Gilmer et al..\n",
    "\n",
    "        This class implements the whole Gilmer et al. model following the functions Message, Update and Readout.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_n : int list\n",
    "            Sizes for the node and edge features.\n",
    "        hidden_state_size : int\n",
    "            Size of the hidden states (the input will be padded with 0's to this size).\n",
    "        message_size : int\n",
    "            Message function output vector size.\n",
    "        n_layers : int\n",
    "            Number of iterations Message+Update (weight tying).\n",
    "        l_target : int\n",
    "            Size of the output.\n",
    "        type : str (Optional)\n",
    "            Classification | [Regression (default)]. If classification, LogSoftmax layer is applied to the output vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_n, hidden_state_size, message_size, n_layers, l_target, type='regression'):\n",
    "        super(MPNN, self).__init__()\n",
    "\n",
    "        # Define message\n",
    "        self.m = nn.ModuleList(\n",
    "            [MessageFunction('mpnn', args={'edge_feat': in_n[1], 'in': hidden_state_size, \n",
    "                                           'out': message_size})])\n",
    "\n",
    "        # Define Update\n",
    "        self.u = nn.ModuleList([UpdateFunction('mpnn',args={'in_m': message_size,\n",
    "                                                            'out': hidden_state_size})])\n",
    "\n",
    "        # Define Readout\n",
    "        self.r = ReadoutFunction('mpnn',args={'in': hidden_state_size,\n",
    "                                              'target': l_target})\n",
    "\n",
    "        self.type = type\n",
    "\n",
    "        self.args = {}\n",
    "        self.args['out'] = hidden_state_size\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, g, h_in, e):\n",
    "\n",
    "        h = []\n",
    "\n",
    "        # Padding to some larger dimension d\n",
    "        h_t = torch.cat([h_in, Variable(\n",
    "            torch.zeros(h_in.size(0), h_in.size(1), self.args['out'] - h_in.size(2)).type_as(h_in.data))], 2)\n",
    "\n",
    "        h.append(h_t.clone())\n",
    "\n",
    "        # Layer\n",
    "        for t in range(0, self.n_layers):\n",
    "            e_aux = e.view(-1, e.size(3))\n",
    "\n",
    "            h_aux = h[t].view(-1, h[t].size(2))\n",
    "\n",
    "            m = self.m[0].forward(h[t], h_aux, e_aux)\n",
    "            m = m.view(h[0].size(0), h[0].size(1), -1, m.size(1))\n",
    "\n",
    "            # Nodes without edge set message to 0\n",
    "            m = torch.unsqueeze(g, 3).expand_as(m) * m\n",
    "\n",
    "            m = torch.squeeze(torch.sum(m, 1))\n",
    "\n",
    "            h_t = self.u[0].forward(h[t], m)\n",
    "\n",
    "            # Delete virtual nodes\n",
    "            h_t = (torch.sum(h_in, 2)[..., None].expand_as(h_t) > 0).type_as(h_t) * h_t\n",
    "            h.append(h_t)\n",
    "\n",
    "        # Readout\n",
    "        res = self.r.forward(h)\n",
    "        if self.type == 'classification':\n",
    "            res = torch.sigmoid(res)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c436888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06b81d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "129d2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "lst_imbalance_ratio = []\n",
    "for i in dat_label.values:\n",
    "    class_weights=compute_class_weight('balanced',classes=np.unique(i), y=i)\n",
    "    #print(np.bincount(i))\n",
    "    #print(class_weights)\n",
    "    #ratio = class_weights[1]/class_weights[0]\n",
    "    ratio = class_weights[1]\n",
    "    lst_imbalance_ratio.append(ratio)\n",
    "\n",
    "import math\n",
    "weights = []\n",
    "for i in range(len(lst_imbalance_ratio)):\n",
    "    weights.append(math.log(1+lst_imbalance_ratio[i]))\n",
    "weights = torch.tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f887f582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#点的特征维度，边的特征维度\n",
    "in_n = [len(h_t[0]), len(list(e.values())[0])] \n",
    "#hidden state/embedding维度\n",
    "hidden_state_size = 20\n",
    "#邻居消息m_i维度（聚合后的维度）后面都用d_v表示\n",
    "message_size = 20\n",
    "#GNN层数\n",
    "n_layers = 3\n",
    "#labels数量\n",
    "l_target = len(l)\n",
    "#回归任务\n",
    "type ='classification'\n",
    "#type ='regression'\n",
    "\n",
    "#定义mpnn模型\n",
    "model = MPNN(in_n, hidden_state_size, message_size, n_layers, l_target, type=type)\n",
    "\n",
    "del in_n, hidden_state_size, message_size, n_layers, l_target, type\n",
    "\n",
    "#print('Optimizer')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
    "\n",
    "\n",
    "#回归任务使用MSE 1ose\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n",
    "\n",
    "#评估指标，|a-b|/|b|\n",
    "#evaluation = lambda output, target: torch.mean(torch.abs(output - target) / torch.abs(target))\n",
    "evaluation = lambda output, target: torch.eq(torch.round(output),target).float().mean()\n",
    "\n",
    "\n",
    "lr_step = (args.lr-args.lr*args.lr_decay)/(args.epochs*args.schedule[1] - args.epochs*args.schedule[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca948a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db01307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    \n",
    "    list_loss = []\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (g, h, e, target) in enumerate(train_loader):\n",
    "\n",
    "        # Prepare input data\n",
    "        if args.cuda:\n",
    "            g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "        g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute output\n",
    "        output = model(g, h, e)\n",
    "        train_loss = criterion(output, target)\n",
    "        list_loss.append(train_loss.item())\n",
    "        # Logs\n",
    "        losses.update(train_loss.item(), g.size(0))\n",
    "        accuracy.update(evaluation(output, target).item(), g.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.log_interval == 0 and i > 0:\n",
    "\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Accuracy {err.val:.4f} ({err.avg:.4f})'\n",
    "                  .format(epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                          data_time=data_time, loss=losses, err=accuracy))\n",
    "\n",
    "    print('Epoch: [{0}] Accuracy {err.avg:.3f}; Average Loss {loss.avg:.3f}; Avg Time x Batch {b_time.avg:.3f}'\n",
    "          .format(epoch, err=accuracy, loss=losses, b_time=batch_time))\n",
    "    \n",
    "    return list_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f94cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, evaluation, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (g, h, e, target) in enumerate(val_loader):\n",
    "\n",
    "        # Prepare input data\n",
    "        if args.cuda:\n",
    "            g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "        g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "        # Compute output\n",
    "        output = model(g, h, e)\n",
    "\n",
    "        # Logs\n",
    "        losses.update(criterion(output, target).item(), g.size(0))\n",
    "        accuracy.update(evaluation(output, target).item(), g.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    print(' * Average accuracy {err.avg:.3f}; '\n",
    "          .format(err=accuracy))\n",
    "\n",
    "\n",
    "    return accuracy.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4570a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check cuda\n",
      "\t* Cuda\n",
      "Epoch: [0][100/449]\tTime 0.037 (0.047)\tData 0.009 (0.016)\tLoss 43.0878 (36.9493)\tAccuracy 0.7363 (0.6685)\n",
      "Epoch: [0][200/449]\tTime 0.476 (0.055)\tData 0.013 (0.019)\tLoss 32.5630 (36.3721)\tAccuracy 0.7659 (0.7089)\n",
      "Epoch: [0][300/449]\tTime 0.061 (0.054)\tData 0.020 (0.019)\tLoss 39.0173 (36.6581)\tAccuracy 0.7582 (0.7327)\n",
      "Epoch: [0][400/449]\tTime 0.035 (0.056)\tData 0.007 (0.020)\tLoss 22.9888 (36.7127)\tAccuracy 0.7681 (0.7388)\n",
      "Epoch: [0] Accuracy 0.743; Average Loss 36.896; Avg Time x Batch 0.054\n",
      " * Average accuracy 0.782; \n",
      "Epoch: [1][100/449]\tTime 0.112 (0.057)\tData 0.058 (0.021)\tLoss 28.9061 (36.9005)\tAccuracy 0.7703 (0.7752)\n",
      "Epoch: [1][200/449]\tTime 0.040 (0.055)\tData 0.007 (0.020)\tLoss 37.2949 (36.2939)\tAccuracy 0.7703 (0.7726)\n",
      "Epoch: [1][300/449]\tTime 0.050 (0.053)\tData 0.025 (0.019)\tLoss 36.1708 (36.6058)\tAccuracy 0.7802 (0.7711)\n",
      "Epoch: [1][400/449]\tTime 0.045 (0.055)\tData 0.008 (0.020)\tLoss 37.2114 (36.5785)\tAccuracy 0.7451 (0.7718)\n",
      "Epoch: [1] Accuracy 0.771; Average Loss 36.439; Avg Time x Batch 0.054\n",
      " * Average accuracy 0.768; \n",
      "Epoch: [2][100/449]\tTime 0.073 (0.060)\tData 0.047 (0.023)\tLoss 31.8140 (35.3951)\tAccuracy 0.8165 (0.7640)\n",
      "Epoch: [2][200/449]\tTime 0.035 (0.060)\tData 0.007 (0.022)\tLoss 34.3250 (36.0793)\tAccuracy 0.7495 (0.7693)\n",
      "Epoch: [2][300/449]\tTime 0.170 (0.055)\tData 0.010 (0.019)\tLoss 35.8776 (35.9555)\tAccuracy 0.7659 (0.7699)\n",
      "Epoch: [2][400/449]\tTime 0.048 (0.056)\tData 0.010 (0.020)\tLoss 49.8163 (36.2790)\tAccuracy 0.7791 (0.7680)\n",
      "Epoch: [2] Accuracy 0.770; Average Loss 36.022; Avg Time x Batch 0.055\n",
      " * Average accuracy 0.787; \n",
      "Epoch: [3][100/449]\tTime 0.037 (0.054)\tData 0.008 (0.019)\tLoss 41.1783 (36.0267)\tAccuracy 0.7604 (0.7683)\n",
      "Epoch: [3][200/449]\tTime 0.043 (0.054)\tData 0.011 (0.019)\tLoss 21.6505 (35.3947)\tAccuracy 0.7835 (0.7715)\n",
      "Epoch: [3][300/449]\tTime 0.037 (0.052)\tData 0.008 (0.018)\tLoss 34.8331 (35.8449)\tAccuracy 0.7549 (0.7706)\n",
      "Epoch: [3][400/449]\tTime 0.039 (0.056)\tData 0.011 (0.020)\tLoss 53.5160 (36.0876)\tAccuracy 0.7505 (0.7697)\n",
      "Epoch: [3] Accuracy 0.771; Average Loss 35.935; Avg Time x Batch 0.055\n",
      " * Average accuracy 0.796; \n",
      "Epoch: [4][100/449]\tTime 0.044 (0.050)\tData 0.012 (0.016)\tLoss 25.7897 (35.8224)\tAccuracy 0.7747 (0.7829)\n",
      "Epoch: [4][200/449]\tTime 0.055 (0.055)\tData 0.022 (0.019)\tLoss 32.7318 (36.3113)\tAccuracy 0.7560 (0.7726)\n",
      "Epoch: [4][300/449]\tTime 0.033 (0.052)\tData 0.005 (0.018)\tLoss 31.6118 (35.8928)\tAccuracy 0.7681 (0.7720)\n",
      "Epoch: [4][400/449]\tTime 0.042 (0.055)\tData 0.010 (0.019)\tLoss 38.3829 (35.9370)\tAccuracy 0.7659 (0.7694)\n",
      "Epoch: [4] Accuracy 0.769; Average Loss 35.875; Avg Time x Batch 0.056\n",
      " * Average accuracy 0.767; \n"
     ]
    }
   ],
   "source": [
    "print('Check cuda')\n",
    "if args.cuda:\n",
    "    print('\\t* Cuda')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if torch.is_tensor(v):\n",
    "                state[k] = v.cuda()\n",
    "\n",
    "\n",
    "# Epoch for loop\n",
    "for epoch in range(0, args.epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if epoch > args.epochs * args.schedule[0] and epoch < args.epochs * args.schedule[1]:\n",
    "        args.lr -= lr_step\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = args.lr\n",
    "\n",
    "    # train for one epoch\n",
    "    lst_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    # evaluate on test set\n",
    "    er1 = validate(valid_loader, model, criterion, evaluation)\n",
    "    \n",
    "    is_best = er1 > best_er1\n",
    "    best_er1 = min(er1, best_er1)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "92027304",
   "metadata": {},
   "source": [
    "# For testing\n",
    "validate(test_loader, model, criterion, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "231ad2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t* Cuda\n"
     ]
    }
   ],
   "source": [
    "# For testing\n",
    "report = []\n",
    "all_pred = []\n",
    "all_target =[]\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "accuracy = AverageMeter()\n",
    "\n",
    "if args.cuda:\n",
    "    print('\\t* Cuda')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "for i, (g, h, e, target) in enumerate(test_loader):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Prepare input data\n",
    "    if args.cuda:\n",
    "        g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "    g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "    # Compute output\n",
    "    output =model(g, h, e)\n",
    "    preds = torch.round(output)\n",
    "    \n",
    "    all_pred.append(preds.cpu().detach().numpy())\n",
    "    all_target.append(target.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "255c8158",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = np.vstack(all_pred)\n",
    "all_target = np.vstack(all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1b548f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6137538101492864"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(all_target, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4922875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6022206959706959\n",
      "0.7469755469755469\n",
      "0.6513295099061522\n",
      "0.8402173913043478\n",
      "0.6674588086185044\n",
      "0.5\n",
      "0.5636281588447654\n",
      "0.7269942067736185\n",
      "0.6962218159658744\n",
      "0.538370210469509\n",
      "0.5\n",
      "0.6921389396709324\n",
      "0.6911167157068796\n",
      "0.6180173992673993\n",
      "0.5977252561103492\n",
      "0.5\n",
      "0.5855998591673268\n",
      "0.6888489208633094\n",
      "0.6854568854568854\n",
      "0.8621659634317862\n",
      "0.6149886511024644\n",
      "0.5956937799043063\n",
      "0.5\n",
      "0.7629104108232965\n",
      "0.5\n",
      "0.47475041194145584\n",
      "0.5\n",
      "0.4918181818181818\n",
      "0.5\n",
      "0.5635131471943616\n",
      "0.5\n",
      "0.6837643541050354\n",
      "0.7011846405228759\n",
      "0.6199759720401923\n",
      "0.6269349845201238\n",
      "0.5055710306406686\n",
      "0.9316939890710382\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5212630506748154\n",
      "0.624400479616307\n",
      "0.6100812435545943\n",
      "0.6985374771480803\n",
      "0.5\n",
      "0.5515920129519698\n",
      "0.7096774193548386\n",
      "0.5\n",
      "0.7793764988009592\n",
      "0.5748626373626373\n",
      "0.5\n",
      "0.5\n",
      "0.6276767807465873\n",
      "0.4936708860759494\n",
      "0.5\n",
      "0.5957564575645756\n",
      "0.6427216047709408\n",
      "0.6931039118161044\n",
      "0.6253205128205128\n",
      "0.9293577981651376\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.6787822878228782\n",
      "0.7656916514320535\n",
      "0.5\n",
      "0.6482342007434945\n",
      "0.5\n",
      "0.5\n",
      "0.4955116696588869\n",
      "0.7538528642047106\n",
      "0.855764411027569\n",
      "0.7082776292335116\n",
      "0.6042796865581676\n",
      "0.8832142356732521\n",
      "0.5757246376811594\n",
      "0.6823104693140795\n",
      "0.5759057971014492\n",
      "0.5984111543450065\n",
      "0.5\n",
      "0.9446564885496183\n",
      "0.5\n",
      "0.5\n",
      "0.5407575757575758\n",
      "0.5119023704298915\n",
      "0.857608695652174\n",
      "0.6370024229837313\n",
      "0.5\n",
      "0.5\n",
      "0.6965429446632454\n",
      "0.632480921140715\n"
     ]
    }
   ],
   "source": [
    "for i in range(91):\n",
    "    print(roc_auc_score(np.transpose(all_target)[i], np.transpose(all_pred)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = classification_report(all_target, all_pred,output_dict=True)\n",
    "report = pd.DataFrame.from_dict(cl, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "492530cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.134831</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097345</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.181360</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.130152</td>\n",
       "      <td>0.756108</td>\n",
       "      <td>0.222077</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.076969</td>\n",
       "      <td>0.473630</td>\n",
       "      <td>0.122309</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.160144</td>\n",
       "      <td>0.756108</td>\n",
       "      <td>0.253855</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.774445</td>\n",
       "      <td>0.216046</td>\n",
       "      <td>2251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "0              0.078125  0.312500  0.125000       16\n",
       "1              0.085106  0.571429  0.148148        7\n",
       "2              0.080000  0.428571  0.134831       14\n",
       "3              0.108108  0.800000  0.190476       10\n",
       "4              0.097345  0.916667  0.176000       36\n",
       "...                 ...       ...       ...      ...\n",
       "90             0.181360  0.935065  0.303797       77\n",
       "micro avg      0.130152  0.756108  0.222077     2251\n",
       "macro avg      0.076969  0.473630  0.122309     2251\n",
       "weighted avg   0.160144  0.756108  0.253855     2251\n",
       "samples avg    0.132223  0.774445  0.216046     2251\n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02e8fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.to_csv(\"report1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ed3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
