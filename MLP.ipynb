{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38df23e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4993513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_label = pd.read_csv('dataset.csv',index_col=0).T\n",
    "#label = label.iloc[:12,:]\n",
    "dat_smiles = pd.read_csv('smiles.csv', index_col=0)\n",
    "s = dat_smiles.to_dict()\n",
    "dict_smile = s['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50fb834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CID100031      0\n",
       "CID10012081    0\n",
       "CID10015       0\n",
       "CID100197      0\n",
       "CID10024       0\n",
       "              ..\n",
       "CID99870       0\n",
       "CID9989        0\n",
       "CID9989226     1\n",
       "CID999         0\n",
       "CID9990075     0\n",
       "Name: odorless, Length: 5596, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_label.iloc[:,57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a170337e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "# create descriptor calculator with all descriptors\n",
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "\n",
    "len(calc.descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1f339c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [Chem.MolFromSmiles(smi) for smi in dict_smile.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fd3730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                       | 132/5596 [00:03<03:43, 24.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                    | 446/5596 [00:10<01:39, 51.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▊                                  | 821/5596 [00:18<01:28, 53.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████                                 | 988/5596 [00:22<01:18, 58.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████▏                               | 1036/5596 [00:23<01:20, 56.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▍                             | 1358/5596 [00:30<01:31, 46.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████▊                         | 1989/5596 [00:43<03:07, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5596/5596 [01:54<00:00, 48.72it/s]\n"
     ]
    }
   ],
   "source": [
    "df = calc.pandas(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f408ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('mordred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84059bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544da64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5a5e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb1fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F   # 激励函数的库\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db273e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_253031/216529726.py:1: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,15,16,54,55,56,57,58,59,60,61,62,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,136,137,138,139,145,146,147,148,153,154,155,156,157,163,164,165,166,172,173,174,175,181,182,183,184,189,190,191,192,193,198,199,200,201,202,207,208,209,210,211,217,218,219,220,226,227,228,229,234,235,236,237,238,239,240,241,242,261,262,263,264,265,266,267,268,269,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,342,343,344,345,346,352,353,354,355,361,362,363,364,369,370,371,372,373,379,380,381,382,388,389,390,391,397,398,399,400,405,406,407,408,409,414,415,416,417,418,423,424,425,426,427,433,434,435,436,442,443,444,445,450,451,452,453,458,459,460,461,466,467,468,469,474,475,476,477,482,483,484,485,490,491,492,493,498,499,500,501,506,507,508,509,514,515,516,517,522,523,524,525,530,531,532,533,538,539,540,541,546,547,548,549,554,555,556,557,562,563,564,565,570,571,572,573,578,579,580,581,586,587,588,589,594,595,596,597,602,603,604,605,610,611,612,613,618,619,620,621,626,627,628,629,634,635,636,637,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,781,782,792,818,826,827,828,829,834,842,843,844,845,853,854,855,861,862,863,880,881,882,883,884,885,886,887,888,889,890,891,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1300,1301,1302,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1553,1581,1582,1583,1584,1612) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('mordred.csv',index_col=0)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('mordred.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e38eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_label = pd.read_csv('dataset.csv',index_col=0).T\n",
    "#label = label.iloc[:12,:]\n",
    "dat_smiles = pd.read_csv('smiles.csv', index_col=0)\n",
    "s = dat_smiles.to_dict()\n",
    "dict_smile = s['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "411afb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.select_dtypes(include=[int, float]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6a17c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dat_label.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54a9e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor(y, dtype=torch.float) \n",
    "X=torch.tensor(X, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ada7a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, data1, label ,transform = None):\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data1 = data1\n",
    "        self.label = label\n",
    "\n",
    "        self.datanum = len(data1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        out_data1 = torch.tensor(self.data1[idx]).float()\n",
    "        out_label = torch.tensor(self.label[idx])\n",
    "        if self.transform:\n",
    "            out_data1 = self.transform(out_data1)\n",
    "\n",
    "        return out_data1, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "870fe42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 5036\n",
      "test data: 560\n"
     ]
    }
   ],
   "source": [
    "train_dat, test_dat, train_label, test_label = train_test_split(X, y, test_size = 0.1, stratify = None,random_state = 66)    \n",
    "print('train data:',len(train_dat))\n",
    "print('test data:',len(test_dat))\n",
    "\n",
    "\n",
    "train_data_set = Mydatasets(data1 = train_dat, label = train_label)\n",
    "test_data_set = Mydatasets(data1 = test_dat, label = test_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data_set, batch_size = 64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_set, batch_size = 64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3ee3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69d582d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):   # 继承 torch 的 Module\n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()    # \n",
    "        # 初始化三层神经网络 两个全连接的隐藏层，一个输出层\n",
    "        self.fc1 = torch.nn.Linear(697,512)  # 第一个隐含层  \n",
    "        self.fc2 = torch.nn.Linear(512,128)  # 第二个隐含层\n",
    "        self.fc3 = torch.nn.Linear(128,91)   # 输出层\n",
    "        \n",
    "    def forward(self,din):\n",
    "        # 前向传播， 输入值：din, 返回值 dout\n",
    "        din = din.view(-1,697)       # 将一个多行的Tensor,拼接成一行\n",
    "        dout = F.relu(self.fc1(din))   # 使用 relu 激活函数\n",
    "        dout = F.relu(self.fc2(dout))\n",
    "        dout = F.softmax(self.fc3(dout), dim=1)  # 输出层使用 softmax 激活函数\n",
    "        # 10个数字实际上是10个类别，输出是概率分布，最后选取概率最大的作为预测值输出\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c450d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练神经网络\n",
    "def train():\n",
    "    #定义损失函数和优化器\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(params = model.parameters(), lr = 0.01)\n",
    "    # 开始训练\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        for data,target in train_loader:\n",
    "            optimizer.zero_grad()   # 清空上一步的残余更新参数值\n",
    "            output = model(data)    # 得到预测值\n",
    "            loss = lossfunc(output,target)  # 计算两者的误差\n",
    "            loss.backward()         # 误差反向传播, 计算参数更新值\n",
    "            optimizer.step()        # 将参数更新值施加到 net 的 parameters 上\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        print('Epoch:  {}  \\tTraining Loss: {:.6f}'.format(epoch + 1, train_loss))\n",
    "        # 每遍历一遍数据集，测试一下准确率\n",
    "        test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "28cdba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_253031/4241691745.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_data1 = torch.tensor(self.data1[idx]).float()\n",
      "/tmp/ipykernel_253031/4241691745.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_label = torch.tensor(self.label[idx])\n"
     ]
    }
   ],
   "source": [
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fe8e9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 91])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab471c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 91])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8003aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在数据集上测试神经网络\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 训练集中不需要反向传播\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            #_, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = torch.sigmoid(outputs.data)\n",
    "            total += labels.size(0) * labels.size(1)\n",
    "            correct += (torch.round(predicted) == labels).sum().item()\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    return 100.0 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0e7a8688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 声明感知器网络\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c1fb42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义全局变量\n",
    "n_epochs = 10     # epoch 的数目\n",
    "batch_size = 64  # 决定每次读取多少图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e41e63c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_253031/4241691745.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_data1 = torch.tensor(self.data1[idx]).float()\n",
      "/tmp/ipykernel_253031/4241691745.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out_label = torch.tensor(self.label[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1  \tTraining Loss: 18.350484\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  2  \tTraining Loss: 18.343995\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  3  \tTraining Loss: 18.343994\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  4  \tTraining Loss: 18.343992\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  5  \tTraining Loss: 18.343990\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  6  \tTraining Loss: 18.343985\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  7  \tTraining Loss: 18.343974\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  8  \tTraining Loss: 18.343946\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  9  \tTraining Loss: 18.343869\n",
      "Accuracy of the network on the test images: 94 %\n",
      "Epoch:  10  \tTraining Loss: 18.343798\n",
      "Accuracy of the network on the test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ff4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181535d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3347cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805bf24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646550eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fe86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
