{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a9f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import ChemicalFeatures\n",
    "from rdkit import RDConfig\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd.variable import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#import multiprocessing\n",
    "#from joblib import Parallel, delayed\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdbb8bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19ef3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "/bin/bash: nvidia-smi: command not found\n",
      "/bin/bash: gpustat: command not found\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "!nvidia-smi\n",
    "torch.cuda.is_available()\n",
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593ce43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from skmultilearn.dataset import load_from_arff, load_dataset_dump\n",
    "import copy\n",
    "import datetime\n",
    "import jsonpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d2eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import pandas as pd\n",
    "import copy\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05404d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import str\n",
    "from builtins import range\n",
    "from builtins import object\n",
    "import arff\n",
    "import bz2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "from os import environ\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "from os.path import exists\n",
    "from os.path import expanduser\n",
    "from os.path import isdir\n",
    "from os.path import splitext\n",
    "from os import listdir\n",
    "from os import makedirs\n",
    "from scipy import sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba95f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd71162",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_label = pd.read_csv('dataset.csv',index_col=0)\n",
    "#label = label.iloc[:12,:]\n",
    "dat_smiles = pd.read_csv('smiles.csv', index_col=0)\n",
    "s = dat_smiles.to_dict()\n",
    "dict_smile = s['SMILES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124de90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_labels = dat_label.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f6cf1",
   "metadata": {},
   "source": [
    "del 11980947,5287407,24238,44475014,62074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1809f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID100031</th>\n",
       "      <th>CID10012081</th>\n",
       "      <th>CID10015</th>\n",
       "      <th>CID100197</th>\n",
       "      <th>CID10024</th>\n",
       "      <th>CID100240</th>\n",
       "      <th>CID1004</th>\n",
       "      <th>CID10045</th>\n",
       "      <th>CID10049</th>\n",
       "      <th>CID100495</th>\n",
       "      <th>...</th>\n",
       "      <th>CID99643</th>\n",
       "      <th>CID9964407</th>\n",
       "      <th>CID997</th>\n",
       "      <th>CID998</th>\n",
       "      <th>CID99818</th>\n",
       "      <th>CID99870</th>\n",
       "      <th>CID9989</th>\n",
       "      <th>CID9989226</th>\n",
       "      <th>CID999</th>\n",
       "      <th>CID9990075</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aldehydic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>almond</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animal</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anisic</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetable</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>violet</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warm</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waxy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woody</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 5596 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CID100031  CID10012081  CID10015  CID100197  CID10024  CID100240  \\\n",
       "aldehydic          0            0         0          0         0          0   \n",
       "almond             0            0         0          0         0          0   \n",
       "animal             0            0         0          0         0          0   \n",
       "anisic             0            0         0          0         0          0   \n",
       "apple              0            0         0          0         0          0   \n",
       "...              ...          ...       ...        ...       ...        ...   \n",
       "vegetable          0            0         0          0         0          1   \n",
       "violet             0            0         0          0         0          0   \n",
       "warm               0            0         0          0         0          0   \n",
       "waxy               0            0         0          0         0          0   \n",
       "woody              0            0         0          0         0          1   \n",
       "\n",
       "           CID1004  CID10045  CID10049  CID100495  ...  CID99643  CID9964407  \\\n",
       "aldehydic        0         0         0          0  ...         0           0   \n",
       "almond           0         0         0          0  ...         0           0   \n",
       "animal           0         0         0          0  ...         0           0   \n",
       "anisic           0         0         0          0  ...         0           0   \n",
       "apple            0         0         0          0  ...         0           0   \n",
       "...            ...       ...       ...        ...  ...       ...         ...   \n",
       "vegetable        0         0         0          0  ...         0           0   \n",
       "violet           0         0         0          0  ...         0           0   \n",
       "warm             0         0         0          0  ...         0           0   \n",
       "waxy             0         0         0          0  ...         0           0   \n",
       "woody            0         0         1          0  ...         0           0   \n",
       "\n",
       "           CID997  CID998  CID99818  CID99870  CID9989  CID9989226  CID999  \\\n",
       "aldehydic       0       0         0         0        0           0       0   \n",
       "almond          1       0         0         0        0           0       0   \n",
       "animal          0       0         1         0        0           0       1   \n",
       "anisic          0       0         0         0        0           0       0   \n",
       "apple           0       0         0         0        0           0       0   \n",
       "...           ...     ...       ...       ...      ...         ...     ...   \n",
       "vegetable       0       0         0         0        0           0       0   \n",
       "violet          0       0         0         0        0           0       0   \n",
       "warm            0       0         0         0        0           0       0   \n",
       "waxy            0       0         0         0        0           0       1   \n",
       "woody           0       0         0         0        1           0       0   \n",
       "\n",
       "           CID9990075  \n",
       "aldehydic           0  \n",
       "almond              0  \n",
       "animal              0  \n",
       "anisic              0  \n",
       "apple               0  \n",
       "...               ...  \n",
       "vegetable           0  \n",
       "violet              0  \n",
       "warm                0  \n",
       "waxy                0  \n",
       "woody               0  \n",
       "\n",
       "[91 rows x 5596 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5ec676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def szymanski_ts_eq_fold(n_splits, y):\n",
    "\n",
    "    y_train = lil_matrix(y)\n",
    "\n",
    "    n_samples = y_train.shape[0] #593\n",
    "    n_labels = y_train.shape[1] #6\n",
    "\n",
    "    percentage_per_fold = [1/float(n_splits) for i in range(n_splits)]\n",
    "    desired_samples_per_fold = np.array([percentage_per_fold[i]*n_samples for i in range(n_splits)]) #59.3\n",
    "\n",
    "    folds = [[] for i in range(n_splits)] #10 lists\n",
    "\n",
    "    samples_with_label = [[] for i in range(n_labels)]\n",
    "\n",
    "    for sample, labels in enumerate(y_train.rows):\n",
    "        for label in labels:\n",
    "            samples_with_label[label].append(sample)\n",
    "    # labelpair based sample size\n",
    "            \n",
    "    samples_with_labelpairs = {}\n",
    "    for row, labels in enumerate(y_train.rows):\n",
    "        pairs = [(a, b) for b in labels for a in labels if a <= b]\n",
    "        for p in pairs:\n",
    "            if p not in samples_with_labelpairs:\n",
    "                samples_with_labelpairs[p] = []\n",
    "            samples_with_labelpairs[p].append(row)\n",
    "\n",
    "    desired_samples_per_labelpair_per_fold = {k : [len(v)*i for i in percentage_per_fold] for k,v in samples_with_labelpairs.items()}\n",
    "\n",
    "    labels_of_edges = samples_with_labelpairs.keys() # 20 pairs\n",
    "    labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges] #XXXXXX\n",
    "    # labelpair based sample size\n",
    "    \n",
    "    rows_used = {i : False for i in range(n_samples)}\n",
    "    total_labeled_samples_available = sum(labeled_samples_available) #1723\n",
    "    old_l=None\n",
    "\n",
    "    while total_labeled_samples_available > 0:\n",
    "        l = list(labels_of_edges)[np.argmin(np.ma.masked_equal(labeled_samples_available, 0, copy=False))]\n",
    "\n",
    "        while len(samples_with_labelpairs[l])>0:\n",
    "\n",
    "            row = samples_with_labelpairs[l].pop()\n",
    "            if rows_used[row]:\n",
    "                continue\n",
    "\n",
    "            max_val = max(desired_samples_per_labelpair_per_fold[l])\n",
    "            M = np.where(np.array(desired_samples_per_labelpair_per_fold[l])==max_val)[0]\n",
    "            print(l, M, len(M))\n",
    "\n",
    "            m = None\n",
    "            if len(M) == 1:\n",
    "                m = M[0]\n",
    "            else:\n",
    "                max_val = max(desired_samples_per_fold[M])\n",
    "                M_bis = np.where(np.array(desired_samples_per_fold)==max_val)[0]\n",
    "                M_bis = np.array([x for x in M_bis if x in M])\n",
    "                m = np.random.choice(M_bis, 1)[0]\n",
    "                #print(M_prim,m, max_val, desired_samples_per_labelpair_per_fold[l])\n",
    "\n",
    "            folds[m].append(row)\n",
    "            rows_used[row]=True #----\n",
    "            desired_samples_per_labelpair_per_fold[l][m]-=1\n",
    "            if desired_samples_per_labelpair_per_fold[l][m] <0:\n",
    "                desired_samples_per_labelpair_per_fold[l][m]=0\n",
    "\n",
    "            for i in samples_with_labelpairs.keys():\n",
    "                if row in samples_with_labelpairs[i]:\n",
    "                    samples_with_labelpairs[i].remove(row)\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]-=1\n",
    "\n",
    "                if desired_samples_per_labelpair_per_fold[i][m] <0:\n",
    "                    desired_samples_per_labelpair_per_fold[i][m]=0\n",
    "            desired_samples_per_fold[m]-=1\n",
    "\n",
    "        labeled_samples_available = [len(samples_with_labelpairs[v]) for v in labels_of_edges]\n",
    "        total_labeled_samples_available = sum(labeled_samples_available)\n",
    "\n",
    "        available_samples = [i for i, v in rows_used.items() if not v]\n",
    "        samples_left = len(available_samples)\n",
    "\n",
    "\n",
    "    assert (samples_left + sum(map(len, folds))) == n_samples\n",
    "\n",
    "    while samples_left>0:\n",
    "        row = available_samples.pop()\n",
    "        rows_used[row]=True\n",
    "        fold_selected = np.random.choice(np.where(desired_samples_per_fold>0)[0], 1)[0]\n",
    "        folds[fold_selected].append(row)\n",
    "        samples_left-=1\n",
    "\n",
    "    assert sum(map(len, folds)) == n_samples\n",
    "    assert len([i for i, v in rows_used.items() if not v])==0\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03315ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5596x91 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22713 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.sparse.lil_matrix(dat_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 10\n",
    "folds =szymanski_ts_eq_fold(n_splits, dat_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60368ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fab91d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--model'], dest='model', nargs=None, const=None, default='MPNN', type=<class 'str'>, choices=None, help='MPNN model name [MPNN, MPNNv2, MPNNv3]', metavar=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parser check\n",
    "def restricted_float(x, inter):\n",
    "    x = float(x)\n",
    "    if x < inter[0] or x > inter[1]:\n",
    "        raise argparse.ArgumentTypeError(\"%r not in range [1e-5, 1e-4]\"%(x,))\n",
    "    return x\n",
    "\n",
    "# Argument parser\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Neural message passing')\n",
    "\n",
    "parser.add_argument('--dataset', default='qm9', help='QM9')\n",
    "parser.add_argument('--datasetPath', default='/home/taobai/Documents/Model/MPNN/mpnn-data/qm9/dsgdb9nsd/', help='dataset path')\n",
    "parser.add_argument('--logPath', default='./log/qm9/mpnn/', help='log path')\n",
    "parser.add_argument('--plotLr', default=False, help='allow plotting the data')\n",
    "parser.add_argument('--plotPath', default='./plot/qm9/mpnn/', help='plot path')\n",
    "parser.add_argument('--resume', default='./checkpoint/qm9/mpnn/',\n",
    "                    help='path to latest checkpoint')\n",
    "\n",
    "# Optimization Options\n",
    "parser.add_argument('--batch-size', type=int, default=25, metavar='N',\n",
    "                    help='Input batch size for training (default: 20)')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Enables CUDA training')\n",
    "parser.add_argument('--epochs', type=int, default=200, metavar='N',\n",
    "                    help='Number of epochs to train (default: 100)')\n",
    "parser.add_argument('--lr', type=lambda x: restricted_float(x, [1e-5, 1e-2]), default=1e-3, metavar='LR',\n",
    "                    help='Initial learning rate [1e-5, 5e-4] (default: 1e-4)')\n",
    "parser.add_argument('--lr-decay', type=lambda x: restricted_float(x, [.01, 1]), default=0.6, metavar='LR-DECAY',\n",
    "                    help='Learning rate decay factor [.01, 1] (default: 0.6)')\n",
    "parser.add_argument('--schedule', type=list, default=[0.1, 0.9], metavar='S',\n",
    "                    help='Percentage of epochs to start the learning rate decay [0, 1] (default: [0.1, 0.9])')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum (default: 0.9)')\n",
    "# i/o\n",
    "parser.add_argument('--log-interval', type=int, default=20, metavar='N',\n",
    "                    help='How many batches to wait before logging training status')\n",
    "# Accelerating\n",
    "parser.add_argument('--prefetch', type=int, default=4, help='Pre-fetching threads.')\n",
    "\n",
    "# Model modification\n",
    "parser.add_argument('--model', type=str,help='MPNN model name [MPNN, MPNNv2, MPNNv3]',\n",
    "                        default='MPNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff5b30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='qm9', datasetPath='/home/taobai/Documents/Model/MPNN/mpnn-data/qm9/dsgdb9nsd/', logPath='./log/qm9/mpnn/', plotLr=False, plotPath='./plot/qm9/mpnn/', resume='./checkpoint/qm9/mpnn/', batch_size=25, no_cuda=False, epochs=200, lr=0.001, lr_decay=0.6, schedule=[0.1, 0.9], momentum=0.9, log_interval=20, prefetch=4, model='MPNN')\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57531a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c234a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_er1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f98f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e882a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_graph_reader(CID):\n",
    "    smiles = dict_smile[CID]\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    m = Chem.AddHs(m)\n",
    "   \n",
    "    g = nx.Graph()\n",
    "    # Create nodes\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        atom_i = m.GetAtomWithIdx(i)\n",
    "\n",
    "        g.add_node(i, a_type=atom_i.GetSymbol(), a_num=atom_i.GetAtomicNum(), acceptor=0, donor=0,\n",
    "                   aromatic=atom_i.GetIsAromatic(), hybridization=atom_i.GetHybridization(),\n",
    "                   num_h=atom_i.GetTotalNumHs())\n",
    "\n",
    "\n",
    "    # Read Edges\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        for j in range(0, m.GetNumAtoms()):\n",
    "            e_ij = m.GetBondBetweenAtoms(i, j)\n",
    "            if e_ij is not None:\n",
    "                g.add_edge(i, j, b_type=e_ij.GetBondType())\n",
    "            else:\n",
    "                # Unbonded\n",
    "                g.add_edge(i, j, b_type=None)\n",
    "\n",
    "    l = list(dat_label[CID].values)           \n",
    "                \n",
    "    return g , l"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bf2706b",
   "metadata": {},
   "source": [
    "idx = np.random.permutation(label.shape[1])\n",
    "idx = idx.tolist()\n",
    "\n",
    "# valid_ids = [label.columns[i] for i in idx[0:500]]\n",
    "# test_ids = [label.columns[i] for i in idx[500:1000]]\n",
    "# train_ids =  [label.columns[i] for i in idx[1000:]]\n",
    "\n",
    "valid_ids = [label.columns[i] for i in idx[0:50]]\n",
    "test_ids = [label.columns[i] for i in idx[50:100]]\n",
    "train_ids =  [label.columns[i] for i in idx[100:500]]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f2bb27a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fee0609",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = folds[2]+folds[3]+folds[4]+folds[5]+folds[6]+folds[7]+folds[8]+folds[9]\n",
    "valid_ids = [dat_label.columns[i] for i in folds[0]]\n",
    "test_ids = [dat_label.columns[i] for i in folds[1]]\n",
    "train_ids =  [dat_label.columns[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f86a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_edges(g):\n",
    "    remove_edges = []\n",
    "    e={}    \n",
    "    for n1, n2, d in g.edges(data=True):\n",
    "        e_t = []\n",
    "        # Raw distance function\n",
    "        if d['b_type'] is None:\n",
    "            remove_edges += [(n1, n2)]\n",
    "        else:\n",
    "            #e_t.append(d['distance'])\n",
    "            e_t += [int(d['b_type'] == x) for x in [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE,\n",
    "                                                    rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]]\n",
    "        if e_t:\n",
    "            e[(n1, n2)] = e_t\n",
    "    for edg in remove_edges:\n",
    "        g.remove_edge(*edg)    \n",
    "    \n",
    "    return nx.to_numpy_matrix(g), e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea03898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_nodes(g, hydrogen=False):\n",
    "    h = []\n",
    "    for n, d in g.nodes(data=True): \n",
    "        h_t = []\n",
    "        # Atom type (One-hot H, C, N, O F)\n",
    "        h_t += [int(d['a_type'] == x) for x in ['H', 'C', 'N', 'O', 'F']]\n",
    "        # Atomic number\n",
    "        h_t.append(d['a_num'])\n",
    "        # Acceptor\n",
    "        h_t.append(d['acceptor'])\n",
    "        # Donor\n",
    "        h_t.append(d['donor'])\n",
    "        # Aromatic\n",
    "        h_t.append(int(d['aromatic']))\n",
    "        # If number hydrogen is used as a\n",
    "        if hydrogen:\n",
    "            h_t.append(d['num_h'])\n",
    "        h.append(h_t)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b2a63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qm9():\n",
    "#class Qm9(data.Dataset):\n",
    "    # Constructor\n",
    "    def __init__(self, idx, vertex_transform=qm9_nodes, edge_transform=qm9_edges,\n",
    "                 target_transform=None, e_representation='raw_distance'):\n",
    "        self.idx = idx\n",
    "        self.vertex_transform = vertex_transform\n",
    "        self.edge_transform = edge_transform\n",
    "        self.target_transform = target_transform\n",
    "        #化学分子距离度量方式，有三种，这里用的是'raw_distance'\n",
    "        self.e_representation = e_representation\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #读图，返回networkx类型的图，标签list\n",
    "        #self.ids[index]是根据index得到化学分子文件名\n",
    "        #self.root是路径\n",
    "        g, target = xyz_graph_reader(self.idx[index])\n",
    "        if self.vertex_transform is not None:\n",
    "            h = self.vertex_transform(g)\n",
    "\n",
    "        if self.edge_transform is not None:\n",
    "            g, e = self.edge_transform(g)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        #g：邻接矩阵\n",
    "        #h：每个点的特征（list of list）\n",
    "        #e：词典，key是边，value是特征\n",
    "        #target：标签list\n",
    "        return (g, h, e), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "    def set_target_transform(self, target_transform):\n",
    "        self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "227578a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Qm9(train_ids, edge_transform=qm9_edges, e_representation='raw_distance')\n",
    "data_valid = Qm9(valid_ids, edge_transform=qm9_edges, e_representation='raw_distance')\n",
    "data_test = Qm9(test_ids, edge_transform=qm9_edges, e_representation='raw_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e6d3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87db4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one graph\n",
    "g_tuple, l = data_train[0]\n",
    "g, h_t, e = g_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bebaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(obj, start, end):\n",
    "    vals = []\n",
    "    for i in range(start, end):\n",
    "        vals.append(obj[i][1])\n",
    "    return vals\n",
    "def get_graph_stats(graph_obj_handle):\n",
    "    inputs = len(graph_obj_handle)\n",
    "    res = get_values(graph_obj_handle, 0, inputs) \n",
    "    param = np.array(res)\n",
    "    \n",
    "    stat_dict = {}\n",
    "    \n",
    "    stat_dict['target_mean'] = np.mean(param, axis=0)\n",
    "    stat_dict['target_std'] = np.std(param, axis=0)\n",
    "\n",
    "    return stat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "658957cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_dict = get_graph_stats(data_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90a8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54e2ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_target_transform was defined in Class Qm9\n",
    "data_train.set_target_transform(lambda x:x)\n",
    "data_valid.set_target_transform(lambda x: x)\n",
    "data_test.set_target_transform(lambda x: x)\n",
    "\n",
    "# def normalize_data(data, mean, std):\n",
    "#     data_norm = (data-mean)/std\n",
    "#     return data_norm\n",
    "\n",
    "#data_train.set_target_transform(lambda x: normalize_data(x,stat_dict['target_mean'],stat_dict['target_std']))\n",
    "#data_valid.set_target_transform(lambda x: normalize_data(x, stat_dict['target_mean'],stat_dict['target_std']))\n",
    "#data_test.set_target_transform(lambda x: normalize_data(x, stat_dict['target_mean'],stat_dict['target_std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcd8dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be9d6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_g(batch):\n",
    "\n",
    "    batch_sizes = np.max(np.array([[len(input_b[1]), len(input_b[1][0]), len(input_b[2]),\n",
    "                                len(list(input_b[2].values())[0])]\n",
    "                                if input_b[2] else\n",
    "                                [len(input_b[1]), len(input_b[1][0]), 0,0]\n",
    "                                for (input_b, target_b) in batch]), axis=0)\n",
    "\n",
    "    g = np.zeros((len(batch), batch_sizes[0], batch_sizes[0]))\n",
    "    h = np.zeros((len(batch), batch_sizes[0], batch_sizes[1]))\n",
    "    e = np.zeros((len(batch), batch_sizes[0], batch_sizes[0], batch_sizes[3]))\n",
    "\n",
    "    target = np.zeros((len(batch), len(batch[0][1])))\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "\n",
    "        num_nodes = len(batch[i][0][1])\n",
    "\n",
    "        # Adjacency matrix\n",
    "        g[i, 0:num_nodes, 0:num_nodes] = batch[i][0][0]\n",
    "\n",
    "        # Node features\n",
    "        h[i, 0:num_nodes, :] = batch[i][0][1]\n",
    "\n",
    "        # Edges\n",
    "        for edge in batch[i][0][2].keys():\n",
    "            e[i, edge[0], edge[1], :] = batch[i][0][2][edge]\n",
    "            e[i, edge[1], edge[0], :] = batch[i][0][2][edge]\n",
    "\n",
    "        # Target\n",
    "        target[i, :] = batch[i][1]\n",
    "\n",
    "    g = torch.FloatTensor(g)\n",
    "    h = torch.FloatTensor(h)\n",
    "    e = torch.FloatTensor(e)\n",
    "    target = torch.FloatTensor(target)\n",
    "\n",
    "    return g, h, e, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99e743dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#注意这里面的collate_g函数,在utils里面\n",
    "train_loader = torch.utils.data.DataLoader(data_train,\n",
    "                                           batch_size=args.batch_size,shuffle=True, collate_fn=collate_g,\n",
    "                                           num_workers=args.prefetch, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(data_valid,\n",
    "                                           batch_size=args.batch_size, collate_fn=collate_g,\n",
    "                                           num_workers=args.prefetch, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(data_test,\n",
    "                                          batch_size=args.batch_size, collate_fn=collate_g,\n",
    "                                          num_workers=args.prefetch, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0bb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf39dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c055cc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, hlayers=(91, 256, 128)):\n",
    "        super(NNet, self).__init__()\n",
    "        self.n_hlayers = len(hlayers)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(n_in, hlayers[i]) if i == 0 else\n",
    "                                  nn.Linear(hlayers[i-1], n_out) if i == self.n_hlayers else\n",
    "                                  nn.Linear(hlayers[i-1], hlayers[i]) for i in range(self.n_hlayers+1)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.contiguous().view(-1, self.num_flat_features(x))\n",
    "        for i in range(self.n_hlayers):\n",
    "            x = F.relu(self.fcs[i](x))\n",
    "        x = self.fcs[-1](x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b8d2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "171cb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, message_def='mpnn', args={}):\n",
    "        super(MessageFunction, self).__init__()\n",
    "        self.m_definition = ''\n",
    "        self.m_function = None\n",
    "        self.args = {}\n",
    "        self.__set_message(message_def, args)\n",
    "\n",
    "    # Message from h_v to h_w through e_vw\n",
    "    def forward(self, h_v, h_w, e_vw, args=None):\n",
    "        return self.m_function(h_v, h_w, e_vw, args)\n",
    "\n",
    "    # Set a message function\n",
    "    def __set_message(self, message_def, args={}):\n",
    "        self.m_definition = message_def.lower()\n",
    "\n",
    "        self.m_function = {\n",
    "                    'duvenaud':         self.m_duvenaud,\n",
    "                    'intnet':             self.m_intnet,\n",
    "                    'mpnn':             self.m_mpnn,\n",
    "                }.get(self.m_definition, None)\n",
    "\n",
    "        if self.m_function is None:\n",
    "            print('WARNING!: Message Function has not been set correctly\\n\\tIncorrect definition ' + message_def)\n",
    "            quit()\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud': self.init_duvenaud,            \n",
    "            'intnet':     self.init_intnet,\n",
    "            'mpnn':     self.init_mpnn\n",
    "        }.get(self.m_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "        self.m_size = {\n",
    "                'duvenaud':     self.out_duvenaud,            \n",
    "                'intnet':         self.out_intnet,\n",
    "                'mpnn':         self.out_mpnn\n",
    "            }.get(self.m_definition, None)\n",
    "\n",
    "    # Get the name of the used message function\n",
    "    def get_definition(self):\n",
    "        return self.m_definition\n",
    "\n",
    "    # Get the message function arguments\n",
    "    def get_args(self):\n",
    "        return self.args\n",
    "\n",
    "    # Get Output size\n",
    "    def get_out_size(self, size_h, size_e, args=None):\n",
    "        return self.m_size(size_h, size_e, args)\n",
    "    \n",
    "    \n",
    "    # Duvenaud et al. (2015), Convolutional Networks for Learning Molecular Fingerprints\n",
    "    def m_duvenaud(self, h_v, h_w, e_vw, args):\n",
    "        m = torch.cat([h_w, e_vw], 2)\n",
    "        return m\n",
    "\n",
    "    def out_duvenaud(self, size_h, size_e, args):\n",
    "        return size_h + size_e\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args \n",
    "\n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def m_intnet(self, h_v, h_w, e_vw, args):\n",
    "        m = torch.cat([h_v[:, None, :].expand_as(h_w), h_w, e_vw], 2)\n",
    "        b_size = m.size()\n",
    "\n",
    "        m = m.view(-1, b_size[2])\n",
    "\n",
    "        m = self.learn_modules[0](m)\n",
    "        m = m.view(b_size[0], b_size[1], -1)\n",
    "        return m\n",
    "\n",
    "    def out_intnet(self, size_h, size_e, args):\n",
    "        return self.args['out']\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['out']))\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    # Gilmer et al. (2017), Neural Message Passing for Quantum Chemistry\n",
    "    def m_mpnn(self, h_v, h_w, e_vw, opt={}):\n",
    "        # Matrices for each edge\n",
    "        edge_output = self.learn_modules[0](e_vw)\n",
    "        edge_output = edge_output.view(-1, self.args['out'], self.args['in'])\n",
    "\n",
    "        #h_w_rows = h_w[..., None].expand(h_w.size(0), h_v.size(1), h_w.size(1)).contiguous()\n",
    "        h_w_rows = h_w[..., None].expand(h_w.size(0), h_w.size(1), h_v.size(1)).contiguous()\n",
    "\n",
    "        h_w_rows = h_w_rows.view(-1, self.args['in'])\n",
    "\n",
    "        h_multiply = torch.bmm(edge_output, torch.unsqueeze(h_w_rows,2))\n",
    "\n",
    "        m_new = torch.squeeze(h_multiply)\n",
    "\n",
    "        return m_new\n",
    "\n",
    "    def out_mpnn(self, size_h, size_e, args):\n",
    "        return self.args['out']\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix A for each edge label.\n",
    "        learn_modules.append(NNet(n_in=params['edge_feat'], n_out=(params['in']*params['out'])))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "def0681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UpdateFunction.py: Updates the nodes using the previous state and the message.\n",
    "\n",
    "class UpdateFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, update_def='nn', args={}):\n",
    "        super(UpdateFunction, self).__init__()\n",
    "        self.u_definition = ''\n",
    "        self.u_function = None\n",
    "        self.args = {}\n",
    "        self.__set_update(update_def, args)\n",
    "\n",
    "    # Update node hv given message mv\n",
    "    def forward(self, h_v, m_v, opt={}):\n",
    "        return self.u_function(h_v, m_v, opt)\n",
    "\n",
    "    # Set update function\n",
    "    def __set_update(self, update_def, args):\n",
    "        self.u_definition = update_def.lower()\n",
    "\n",
    "        self.u_function = {\n",
    "                    'duvenaud':         self.u_duvenaud,            \n",
    "                    'intnet':             self.u_intnet,\n",
    "                    'mpnn':             self.u_mpnn\n",
    "                }.get(self.u_definition, None)\n",
    "\n",
    "        if self.u_function is None:\n",
    "            print('WARNING!: Update Function has not been set correctly\\n\\tIncorrect definition ' + update_def)\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud':         self.init_duvenaud,            \n",
    "            'intnet':             self.init_intnet,\n",
    "            'mpnn':             self.init_mpnn\n",
    "        }.get(self.u_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "    # Get the name of the used update function\n",
    "    def get_definition(self):\n",
    "        return self.u_definition\n",
    "\n",
    "    # Get the update function arguments\n",
    "    def get_args(self):\n",
    "        return self.args\n",
    "    \n",
    "    # Duvenaud\n",
    "    def u_duvenaud(self, h_v, m_v, opt):\n",
    "\n",
    "        param_sz = self.learn_args[0][opt['deg']].size()\n",
    "        parameter_mat = torch.t(self.learn_args[0][opt['deg']])[None, ...].expand(m_v.size(0), param_sz[1], param_sz[0])\n",
    "        \n",
    "        #print(parameter_mat.size())\n",
    "        #print(m_v.size())\n",
    "        #print(torch.transpose(m_v.unsqueeze(-2), 1, 2).size())\n",
    "\n",
    "        #aux = torch.bmm(parameter_mat, torch.transpose(m_v, 1, 2))\n",
    "        aux = torch.bmm(parameter_mat, torch.transpose(m_v.unsqueeze(-2), 1, 2))\n",
    "\n",
    "        return torch.transpose(torch.nn.Sigmoid()(aux), 1, 2)\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        # Filter degree 0 (the message will be 0 and therefore there is no update\n",
    "        args['deg'] = [i for i in params['deg'] if i!=0]\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix H for each degree.\n",
    "        learn_args.append(torch.nn.Parameter(torch.randn(len(args['deg']), args['in'], args['out'])))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args    \n",
    "\n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def u_intnet(self, h_v, m_v, opt):\n",
    "        if opt['x_v'].ndimension():\n",
    "            input_tensor = torch.cat([h_v, opt['x_v'], torch.squeeze(m_v)], 1)\n",
    "        else:\n",
    "            input_tensor = torch.cat([h_v, torch.squeeze(m_v)], 1)\n",
    "\n",
    "        return self.learn_modules[0](input_tensor)\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in'] = params['in']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['out']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    def u_mpnn(self, h_v, m_v, opt={}):\n",
    "        h_in = h_v.view(-1,h_v.size(2))\n",
    "        m_in = m_v.view(-1,m_v.size(2))\n",
    "        h_new = self.learn_modules[0](m_in[None,...],h_in[None,...])[0] # 0 or 1???\n",
    "        return torch.squeeze(h_new).view(h_v.size())\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['in_m'] = params['in_m']\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # GRU\n",
    "        learn_modules.append(nn.GRU(params['in_m'], params['out']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f66f3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReadoutFunction\n",
    "#dtype = torch.cuda.FloatTensor\n",
    "dtype = torch.FloatTensor\n",
    "\n",
    "class ReadoutFunction(nn.Module):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, readout_def='nn', args={}):\n",
    "        super(ReadoutFunction, self).__init__()\n",
    "        self.r_definition = ''\n",
    "        self.r_function = None\n",
    "        self.args = {}\n",
    "        self.__set_readout(readout_def, args)\n",
    "\n",
    "    # Readout graph given node values at las layer\n",
    "    def forward(self, h_v):\n",
    "        return self.r_function(h_v)\n",
    "\n",
    "    # Set a readout function\n",
    "    def __set_readout(self, readout_def, args):\n",
    "        self.r_definition = readout_def.lower()\n",
    "\n",
    "        self.r_function = {\n",
    "                    'duvenaud': self.r_duvenaud,            \n",
    "                    'intnet':     self.r_intnet,\n",
    "                    'mpnn':     self.r_mpnn\n",
    "                }.get(self.r_definition, None)\n",
    "\n",
    "        if self.r_function is None:\n",
    "            print('WARNING!: Readout Function has not been set correctly\\n\\tIncorrect definition ' + readout_def)\n",
    "            quit()\n",
    "\n",
    "        init_parameters = {\n",
    "            'duvenaud': self.init_duvenaud,            \n",
    "            'intnet':     self.init_intnet,\n",
    "            'mpnn':     self.init_mpnn\n",
    "        }.get(self.r_definition, lambda x: (nn.ParameterList([]), nn.ModuleList([]), {}))\n",
    "\n",
    "        self.learn_args, self.learn_modules, self.args = init_parameters(args)\n",
    "\n",
    "    # Get the name of the used readout function\n",
    "    def get_definition(self):\n",
    "        return self.r_definition\n",
    "\n",
    "    # Duvenaud\n",
    "    def r_duvenaud(self, h):\n",
    "        # layers\n",
    "        aux = []\n",
    "        for l in range(len(h)):\n",
    "            param_sz = self.learn_args[l].size()\n",
    "            parameter_mat = torch.t(self.learn_args[l])[None, ...].expand(h[l].size(0), param_sz[1],\n",
    "                                                                                      param_sz[0])\n",
    "\n",
    "            aux.append(torch.transpose(torch.bmm(parameter_mat, torch.transpose(h[l], 1, 2)), 1, 2))\n",
    "\n",
    "            for j in range(0, aux[l].size(1)):\n",
    "                # Mask whole 0 vectors\n",
    "                aux[l][:, j, :] = nn.Softmax()(aux[l][:, j, :].clone())*(torch.sum(aux[l][:, j, :] != 0, 1) > 0)[...,None].expand_as(aux[l][:, j, :]).type_as(aux[l])\n",
    "\n",
    "        aux = torch.sum(torch.sum(torch.stack(aux, 3), 3), 1)\n",
    "        return self.learn_modules[0](torch.squeeze(aux))\n",
    "\n",
    "    def init_duvenaud(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        args['out'] = params['out']\n",
    "\n",
    "        # Define a parameter matrix W for each layer.\n",
    "        for l in range(params['layers']):\n",
    "            learn_args.append(nn.Parameter(torch.randn(params['in'][l], params['out'])))\n",
    "\n",
    "        # learn_modules.append(nn.Linear(params['out'], params['target']))\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['out'], n_out=params['target']))\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args    \n",
    "    \n",
    "    \n",
    "    # Battaglia et al. (2016), Interaction Networks\n",
    "    def r_intnet(self, h):\n",
    "\n",
    "        aux = torch.sum(h[-1],1)\n",
    "\n",
    "        return self.learn_modules[0](aux)\n",
    "\n",
    "    def init_intnet(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['target']))\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n",
    "\n",
    "    def r_mpnn(self, h):\n",
    "\n",
    "        aux = Variable( torch.Tensor(h[0].size(0), self.args['out']).type_as(h[0].data).zero_() )\n",
    "        # For each graph\n",
    "        for i in range(h[0].size(0)):\n",
    "            nn_res = nn.Sigmoid()(self.learn_modules[0](torch.cat([h[0][i,:,:], h[-1][i,:,:]], 1)))*self.learn_modules[1](h[-1][i,:,:])\n",
    "\n",
    "            # Delete virtual nodes\n",
    "            nn_res = (torch.sum(h[0][i,:,:],1)[...,None].expand_as(nn_res)>0).type_as(nn_res)* nn_res\n",
    "\n",
    "            aux[i,:] = torch.sum(nn_res,0)\n",
    "\n",
    "        return aux\n",
    "\n",
    "    def init_mpnn(self, params):\n",
    "        learn_args = []\n",
    "        learn_modules = []\n",
    "        args = {}\n",
    "\n",
    "        # i\n",
    "        learn_modules.append(NNet(n_in=2*params['in'], n_out=params['target']))\n",
    "\n",
    "        # j\n",
    "        learn_modules.append(NNet(n_in=params['in'], n_out=params['target']))\n",
    "\n",
    "        args['out'] = params['target']\n",
    "\n",
    "        return nn.ParameterList(learn_args), nn.ModuleList(learn_modules), args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d155c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "class MPNN(nn.Module):\n",
    "    \"\"\"\n",
    "        MPNN as proposed by Gilmer et al..\n",
    "\n",
    "        This class implements the whole Gilmer et al. model following the functions Message, Update and Readout.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_n : int list\n",
    "            Sizes for the node and edge features.\n",
    "        hidden_state_size : int\n",
    "            Size of the hidden states (the input will be padded with 0's to this size).\n",
    "        message_size : int\n",
    "            Message function output vector size.\n",
    "        n_layers : int\n",
    "            Number of iterations Message+Update (weight tying).\n",
    "        l_target : int\n",
    "            Size of the output.\n",
    "        type : str (Optional)\n",
    "            Classification | [Regression (default)]. If classification, LogSoftmax layer is applied to the output vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_n, hidden_state_size, message_size, n_layers, l_target, type='regression'):\n",
    "        super(MPNN, self).__init__()\n",
    "\n",
    "        # Define message\n",
    "        self.m = nn.ModuleList(\n",
    "            [MessageFunction('mpnn', args={'edge_feat': in_n[1], 'in': hidden_state_size, \n",
    "                                           'out': message_size})])\n",
    "\n",
    "        # Define Update\n",
    "        self.u = nn.ModuleList([UpdateFunction('mpnn',args={'in_m': message_size,\n",
    "                                                            'out': hidden_state_size})])\n",
    "\n",
    "        # Define Readout\n",
    "        self.r = ReadoutFunction('mpnn',args={'in': hidden_state_size,\n",
    "                                              'target': l_target})\n",
    "\n",
    "        self.type = type\n",
    "\n",
    "        self.args = {}\n",
    "        self.args['out'] = hidden_state_size\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, g, h_in, e):\n",
    "\n",
    "        h = []\n",
    "\n",
    "        # Padding to some larger dimension d\n",
    "        h_t = torch.cat([h_in, Variable(\n",
    "            torch.zeros(h_in.size(0), h_in.size(1), self.args['out'] - h_in.size(2)).type_as(h_in.data))], 2)\n",
    "\n",
    "        h.append(h_t.clone())\n",
    "\n",
    "        # Layer\n",
    "        for t in range(0, self.n_layers):\n",
    "            e_aux = e.view(-1, e.size(3))\n",
    "\n",
    "            h_aux = h[t].view(-1, h[t].size(2))\n",
    "\n",
    "            m = self.m[0].forward(h[t], h_aux, e_aux)\n",
    "            m = m.view(h[0].size(0), h[0].size(1), -1, m.size(1))\n",
    "\n",
    "            # Nodes without edge set message to 0\n",
    "            m = torch.unsqueeze(g, 3).expand_as(m) * m\n",
    "\n",
    "            m = torch.squeeze(torch.sum(m, 1))\n",
    "\n",
    "            h_t = self.u[0].forward(h[t], m)\n",
    "\n",
    "            # Delete virtual nodes\n",
    "            h_t = (torch.sum(h_in, 2)[..., None].expand_as(h_t) > 0).type_as(h_t) * h_t\n",
    "            h.append(h_t)\n",
    "\n",
    "        # Readout\n",
    "        res = self.r.forward(h)\n",
    "        if self.type == 'classification':\n",
    "            res = F.softmax(res, dim=1)\n",
    "        \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c436888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06b81d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_logger import configure, log_value\n",
    "from torchmetrics import Recall\n",
    "\n",
    "# def error_ratio(pred, target):\n",
    "#     if type(pred) is not np.ndarray:\n",
    "#         pred = np.array(pred)\n",
    "#     if type(target) is not np.ndarray:\n",
    "#         target = np.array(target)       \n",
    "        \n",
    "#     return np.mean(np.divide(np.abs(pred - target), np.abs(target)))\n",
    "\n",
    "# def pred(output):\n",
    "#     pred = F.softmax(output, dim=1)\n",
    "#     pred  = torch.where(pred> 0.5, 1, pred)\n",
    "#     pred  = torch.where(pred< 0.5, 0, pred)\n",
    "#     return pred\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, log_dir):\n",
    "        if not os.path.isdir(log_dir):\n",
    "            # if the directory does not exist we create the directory\n",
    "            os.makedirs(log_dir)\n",
    "        else:                      \n",
    "            # clean previous logged data under the same directory name\n",
    "            self._remove(log_dir)\n",
    "\n",
    "        # configure the project\n",
    "        configure(log_dir)\n",
    "\n",
    "        self.global_step = 0\n",
    "\n",
    "    def log_value(self, name, value):\n",
    "        log_value(name, value, self.global_step)\n",
    "        return self\n",
    "\n",
    "    def step(self):\n",
    "        self.global_step += 1\n",
    "\n",
    "    @staticmethod\n",
    "    def _remove(path):\n",
    "        \"\"\" param <path> could either be relative or absolute. \"\"\"\n",
    "        if os.path.isfile(path):\n",
    "            os.remove(path)  # remove the file\n",
    "        elif os.path.isdir(path):\n",
    "            import shutil\n",
    "            shutil.rmtree(path)  # remove dir and all contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "129d2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "lst_imbalance_ratio = []\n",
    "for i in dat_label.values:\n",
    "    class_weights=compute_class_weight('balanced',classes=np.unique(i), y=i)\n",
    "    #print(np.bincount(i))\n",
    "    #print(class_weights)\n",
    "    #ratio = class_weights[1]/class_weights[0]\n",
    "    ratio = class_weights[1]\n",
    "    lst_imbalance_ratio.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e05ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "weights = []\n",
    "for i in range(len(lst_imbalance_ratio)):\n",
    "    weights.append(math.log(1+lst_imbalance_ratio[i]))\n",
    "weights = torch.tensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f887f582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#点的特征维度，边的特征维度\n",
    "in_n = [len(h_t[0]), len(list(e.values())[0])] \n",
    "#hidden state/embedding维度\n",
    "hidden_state_size = 20\n",
    "#邻居消息m_i维度（聚合后的维度）后面都用d_v表示\n",
    "message_size = 20\n",
    "#GNN层数\n",
    "n_layers = 3\n",
    "#labels数量\n",
    "l_target = len(l)\n",
    "#回归任务\n",
    "type ='classification'\n",
    "#type ='regression'\n",
    "\n",
    "#定义mpnn模型\n",
    "model = MPNN(in_n, hidden_state_size, message_size, n_layers, l_target, type=type)\n",
    "\n",
    "del in_n, hidden_state_size, message_size, n_layers, l_target, type\n",
    "\n",
    "#print('Optimizer')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
    "\n",
    "\n",
    "#回归任务使用MSE 1ose\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights,reduction='mean')\n",
    "\n",
    "#评估指标，|a-b|/|b|XXXXXXXXXXXXXXXXXXXX\n",
    "#evaluation = lambda output, target: torch.mean(torch.abs(output - target) / torch.abs(target))\n",
    "\n",
    "evaluation = lambda output, target: torch.eq(output,target).float().mean()\n",
    "#evaluation = lambda output, target: torch.eq(pred(output),target.squeeze(dim=-1)).float().mean()\n",
    "\n",
    "\n",
    "#print('Logger')\n",
    "logger = Logger(args.logPath)\n",
    "\n",
    "lr_step = (args.lr-args.lr*args.lr_decay)/(args.epochs*args.schedule[1] - args.epochs*args.schedule[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "617a40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    #recall = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (g, h, e, target) in enumerate(train_loader):\n",
    "\n",
    "        # Prepare input data\n",
    "        if args.cuda:\n",
    "            g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "        g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute output\n",
    "        output = model(g, h, e)\n",
    "        train_loss = criterion(output, target)\n",
    "\n",
    "        # Logs\n",
    "        losses.update(train_loss.item(), g.size(0))\n",
    "        #accuracy.update(evaluation(output, target).item(), g.size(0))\n",
    "        #recall.update(evaluation_r(output, target).item(), g.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.log_interval == 0 and i > 0:\n",
    "\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Accuracy {err.val:.4f} ({err.avg:.4f})'\n",
    "                  .format(epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                          data_time=data_time, loss=losses, err=accuracy))\n",
    "                          \n",
    "    logger.log_value('train_epoch_loss', losses.avg)\n",
    "    logger.log_value('train_epoch_accuracy', accuracy.avg)\n",
    "\n",
    "    print('Epoch: [{0}] Accuracy {err.avg:.3f}; Average Loss {loss.avg:.3f}; Avg Time x Batch {b_time.avg:.3f}'\n",
    "          .format(epoch, err=accuracy, loss=losses, b_time=batch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f94cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, evaluation, logger=None):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    #recall = AverageMeter()\n",
    "\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (g, h, e, target) in enumerate(val_loader):\n",
    "\n",
    "        # Prepare input data\n",
    "        if args.cuda:\n",
    "            g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "        g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "        # Compute output\n",
    "        output = model(g, h, e)\n",
    "\n",
    "        # Logs\n",
    "        losses.update(criterion(output, target).item(), g.size(0))\n",
    "        accuracy.update(evaluation(output, target).item(), g.size(0))\n",
    "        #recall.update(evaluation_r(output, target).item(), g.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "#         if i % args.log_interval == 0 and i > 0:\n",
    "            \n",
    "#             print('Test: [{0}/{1}]\\t'\n",
    "#                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                   'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
    "#                   .format(i, len(val_loader), batch_time=batch_time,\n",
    "#                           loss=losses, err=error_ratio))\n",
    "\n",
    "    print(' * Average accuracy {err.avg:.3f}; '\n",
    "          .format(err=accuracy))\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.log_value('test_epoch_loss', losses.avg)\n",
    "        logger.log_value('test_accuracy', accuracy.avg)\n",
    "        #logger.log_value('test_recall', recall.avg)\n",
    "\n",
    "    return accuracy.avg\n",
    "    #return accuracy.avg,recall.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdfe78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, directory):\n",
    "\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    checkpoint_file = os.path.join(directory, 'checkpoint.pth')\n",
    "    best_model_file = os.path.join(directory, 'model_best.pth')\n",
    "    torch.save(state, checkpoint_file)\n",
    "    if is_best:\n",
    "        shutil.copyfile(checkpoint_file, best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0422d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get the best checkpoint if available without training\n",
    "if args.resume:\n",
    "    checkpoint_dir = args.resume\n",
    "    best_model_file = os.path.join(checkpoint_dir, 'model_best.pth')\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    if os.path.isfile(best_model_file):\n",
    "        print(\"=> loading best model '{}'\".format(best_model_file))\n",
    "        checkpoint = torch.load(best_model_file)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_er1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded best model '{}' (epoch {})\".format(best_model_file, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no best model found at '{}'\".format(best_model_file))\n",
    "\n",
    "print('Check cuda')\n",
    "if args.cuda:\n",
    "    print('\\t* Cuda')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "# Epoch for loop\n",
    "for epoch in range(0, args.epochs):\n",
    "\n",
    "    if epoch > args.epochs * args.schedule[0] and epoch < args.epochs * args.schedule[1]:\n",
    "        args.lr -= lr_step\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = args.lr\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch, logger)\n",
    "\n",
    "    # evaluate on test set\n",
    "    er1 = validate(valid_loader, model, criterion, evaluation,logger)\n",
    "\n",
    "    is_best = er1 > best_er1\n",
    "    best_er1 = min(er1, best_er1)\n",
    "    save_checkpoint({'epoch': epoch + 1, 'state_dict': model.state_dict(), 'best_er1': best_er1,\n",
    "                           'optimizer': optimizer.state_dict(), }, is_best=is_best, directory=args.resume)\n",
    "\n",
    "    # Logger step\n",
    "    logger.log_value('learning_rate', args.lr).step()\n",
    "\n",
    "# get the best checkpoint and test it with test set\n",
    "if args.resume:\n",
    "    checkpoint_dir = args.resume\n",
    "    best_model_file = os.path.join(checkpoint_dir, 'model_best.pth')\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    if os.path.isfile(best_model_file):\n",
    "        print(\"=> loading best model '{}'\".format(best_model_file))\n",
    "        checkpoint = torch.load(best_model_file)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_acc1 = checkpoint['best_er1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if args.cuda:\n",
    "            model.cuda()\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded best model '{}' (epoch {})\".format(best_model_file, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no best model found at '{}'\".format(best_model_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06eb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c7e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "92027304",
   "metadata": {},
   "source": [
    "# For testing\n",
    "validate(test_loader, model, criterion, evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d39d9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23ca86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def auc_score(target,preds):\n",
    "    for i in range(len(target)):\n",
    "        auc_score = roc_auc_score(target[i].cpu().detach().numpy(), preds[i].cpu().detach().numpy())\n",
    "        auc_score = auc_score * len(target)/len(data_test)\n",
    "    return auc_score    \n",
    "    auc = auc_score(target,preds)\n",
    "    aucs = aucs + auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ad2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing\n",
    "report = []\n",
    "all_pred = torch.empty(0,91)\n",
    "all_target = torch.empty(0,91)\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "accuracy = AverageMeter()\n",
    "#auc = AverageMeter()\n",
    "\n",
    "if args.cuda:\n",
    "    print('\\t* Cuda')\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "for i, (g, h, e, target) in enumerate(test_loader):\n",
    "\n",
    "    # Prepare input data\n",
    "    if args.cuda:\n",
    "        g, h, e, target = g.cuda(), h.cuda(), e.cuda(), target.cuda()\n",
    "    g, h, e, target = Variable(g), Variable(h), Variable(e), Variable(target)\n",
    "\n",
    "    # Compute output\n",
    "    output = model(g, h, e)\n",
    "\n",
    "    preds = pred(output)\n",
    "    \n",
    "    \n",
    "    all_pred = torch.cat((all_pred,preds),0)\n",
    "    all_target = torch.cat((all_target,target),0)\n",
    "    \n",
    "    cl = classification_report(target.cpu().detach().numpy(), preds.cpu().detach().numpy(),output_dict=True)\n",
    "    #auc_score = roc_auc_score(target.cpu().detach().numpy(), preds.cpu().detach().numpy())\n",
    "    #print(cl)\n",
    "    report.append(cl)\n",
    "    \n",
    "    # Logs\n",
    "    losses.update(criterion(output, target).item(), g.size(0))\n",
    "    accuracy.update(evaluation(output, target).item(), g.size(0))\n",
    "    #auc.update(roc_auc_score(target.cpu().detach().numpy(), preds.cpu().detach().numpy()), g.size(0))\n",
    "#         if i % args.log_interval == 0 and i > 0:\n",
    "            \n",
    "#             print('Test: [{0}/{1}]\\t'\n",
    "#                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                   'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "#                   'Error Ratio {err.val:.4f} ({err.avg:.4f})'\n",
    "#                   .format(i, len(val_loader), batch_time=batch_time,\n",
    "#                           loss=losses, err=error_ratio))\n",
    "\n",
    "    #print(' * Average accuracy {err.avg:.3f};Average recall {rec.avg:.3f}; Average Loss {loss.avg:.3f}'\n",
    "    #      .format(err=accuracy,rec = recall, loss=losses))\n",
    "\n",
    "    if logger is not None:\n",
    "        logger.log_value('test_epoch_loss', losses.avg)\n",
    "        logger.log_value('test_accuracy', accuracy.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65a9f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aucs = []\n",
    "for i  in range(91):\n",
    "    #auc_score = roc_auc_score(all_target[i].t().cpu().detach().numpy(), all_pred[i].t().cpu().detach().numpy())\n",
    "    auc_score = roc_auc_score(all_target[i].cpu().detach().numpy(), all_pred[i].cpu().detach().numpy())\n",
    "    label_aucs.append(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60e1a9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5207089312701539"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " roc_auc_score(all_target.t().cpu().detach().numpy(), all_pred.t().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfba1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ad1e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in list(cl.keys()):\n",
    "    cols.append('label' + i)\n",
    "df_report = pd.DataFrame(index = cols[:91],columns=report[0]['0'].keys())\n",
    "df_report = df_report.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50384fc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(len(report)):\n",
    "    for l in range(91):\n",
    "        label = '{}'.format(l)\n",
    "        support = report[e][label]['support']\n",
    "        if support != 0:\n",
    "            df_report.iloc[l,0] = df_report.iloc[l,0]+ support * report[e][label]['precision']\n",
    "            #print(report[e][label]['precision'],report[e][label]['recall'],report[e][label]['f1-score'],report[e][label]['support'])\n",
    "            df_report.iloc[l,1] = df_report.iloc[l,1] + support * report[e][label]['recall']\n",
    "            df_report.iloc[l,2] = df_report.iloc[l,2]  + support * report[e][label]['f1-score']\n",
    "            df_report.iloc[l,3] = df_report.iloc[l,3] + report[e][label]['support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0901cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_csv('report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f480b2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label87</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision  recall  f1-score  support\n",
       "label0           0       0       0.0       16\n",
       "label1           0       0       0.0        9\n",
       "label2           0       0       0.0       13\n",
       "label3           0       0       0.0       10\n",
       "label4           0       0       0.0       32\n",
       "...            ...     ...       ...      ...\n",
       "label86          0       0       0.0       32\n",
       "label87          0       0       0.0        8\n",
       "label88          0       0       0.0       12\n",
       "label89          0       0       0.0       49\n",
       "label90          0       0       0.0       77\n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4019e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
